
@book{mcaffer_osgi_2010,
	address = {Boston},
	title = {{OSGi} and {Equinox}},
	publisher = {Addison-Wesley},
	author = {McAffer, Jeff and VanderLei, Paul and Archer, Simon},
	year = {2010}
}

@book{mcaffer_eclipse_2010,
	address = {Boston},
	title = {Eclipse {Rich} {Client} {Platform} {Second} {Edition}},
	publisher = {Addison-Wesley},
	author = {McAffer, Jeff and Lemieux, Jean-Michel and Aniszczyk, Chris},
	year = {2010}
}

@book{burke_restful_2010,
	address = {California},
	title = {{RESTful} {Java} with {JAX}-{RS}},
	publisher = {O-Reilly},
	author = {Burke, Bill},
	year = {2010}
}

@article{gaston_moose:_2009,
	title = {{MOOSE}: {A} parallel computational framework for coupled systems of nonlinear equations},
	volume = {239},
	number = {10},
	journal = {Nuclear Engineering and Design},
	author = {Gaston, Derek and Newman, Chris and Hansen, Glen and Lebrun-Grandie, Damien},
	month = oct,
	year = {2009}
}

@inproceedings{billings_designing_2009,
	address = {New York, NY, USA},
	series = {{CBHPC} '09},
	title = {Designing a {Component}-based {Architecture} for the {Modeling} and {Simulation} of {Nuclear} {Fuels} and {Reactors}},
	isbn = {978-1-60558-718-9},
	url = {http://doi.acm.org/10.1145/1687774.1687780},
	doi = {10.1145/1687774.1687780},
	abstract = {Concerns over the environment and energy security have recently prompted renewed interest in the U. S. in nuclear energy. Recognizing this, the U. S. Dept. of Energy has launched an initiative to revamp and modernize the role that modeling and simulation plays in the development and operation of nuclear facilities. This Nuclear Energy Advanced Modeling and Simulation (NEAMS) program represents a major investment in the development of new software, with one or more large multi-scale multi-physics capabilities in each of four technical areas associated with the nuclear fuel cycle, as well as additional supporting developments. In conjunction with this, we are designing a software architecture, computational environment, and component framework to integrate the NEAMS technical capabilities and make them more accessible to users. In this report of work very much in progress, we lay out the "problem" we are addressing, describe the model-driven system design approach we are using, and compare them with several large-scale technical software initiatives from the past. We discuss how component technology may be uniquely positioned to address the software integration challenges of the NEAMS program, outline the capabilities planned for the NEAMS computational environment and framework, and describe some initial prototyping activities.},
	urldate = {2016-05-25},
	booktitle = {Proceedings of the 2009 {Workshop} on {Component}-{Based} {High} {Performance} {Computing}},
	publisher = {ACM},
	author = {Billings, Jay J. and Elwasif, Wael R. and Hively, Lee M. and Bernholdt, David E. and Hetrick, III, John M. and Bohn, Tim},
	year = {2009},
	pages = {6:1--6:4},
	file = {ACM Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/QSFPPGE8/Billings et al. - 2009 - Designing a Component-based Architecture for the M.pdf:application/pdf}
}

@article{billings_domain-specific_2015,
	title = {A domain-specific analysis system for examining nuclear reactor simulation data for light-water and sodium-cooled fast reactors},
	volume = {85},
	issn = {0306-4549},
	url = {http://www.sciencedirect.com/science/article/pii/S0306454915003606},
	doi = {10.1016/j.anucene.2015.07.002},
	abstract = {Building a new generation of fission reactors in the United States presents many technical and regulatory challenges. One important challenge is the need to share and present results from new high-fidelity, high-performance simulations in an easily usable way. Since modern multiscale, multi-physics simulations can generate petabytes of data, they will require the development of new techniques and methods to reduce the data to familiar quantities of interest (e.g., pin powers, temperatures) with a more reasonable resolution and size. Furthermore, some of the results from these simulations may be new quantities for which visualization and analysis techniques are not immediately available in the community and need to be developed.

This paper describes a new system for managing high-performance simulation results in a domain-specific way that naturally exposes quantities of interest for light water and sodium-cooled fast reactors. It describes requirements to build such a system and the technical challenges faced in its development at all levels (simulation, user interface, etc.). An example comparing results from two different simulation suites for a single assembly in a light-water reactor is presented, along with a detailed discussion of the system’s requirements and design.},
	urldate = {2016-05-26},
	journal = {Annals of Nuclear Energy},
	author = {Billings, Jay Jay and Deyton, Jordan H. and Forest Hull III, S. and Lingerfelt, Eric J. and Wojtowicz, Anna},
	month = nov,
	year = {2015},
	keywords = {simulation, High-performance computing, LWR, Modeling, Nuclear reactors, SFR},
	pages = {856--868},
	file = {ScienceDirect Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/MNV6WXWF/Billings et al. - 2015 - A domain-specific analysis system for examining nu.pdf:application/pdf;ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/F4WWT46D/S0306454915003606.html:text/html}
}

@inproceedings{mccaskey_scientific_2015,
	address = {Reston VA},
	title = {Scientific {Simulation} with {Eclipse} - {From} {Zero} {Code} to {Running} on {Lots} of {Cores} in 10 {Minutes}},
	url = {https://www.eclipsecon.org/na2016/session/scientific-simulation-eclipse-zero-code-running-lots-cores-10-minutes},
	abstract = {Advanced modeling and simulation is revolutionizing the way we do science. It provides a means to test, predict, visualize, and analyze complex physical phenomena in a controlled manner that inevitably directs future theoretical and experimental endeavors. This truth is recognized by the scientific community, with much effort being directed at the development of advanced software frameworks to streamline the way we do computational science research.},
	urldate = {2016-05-26},
	booktitle = {{EclipseCon} {NA} 2016},
	publisher = {Eclipse Foundation},
	author = {McCaskey},
	month = nov,
	year = {2015},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/XSJZJK9N/scientific-simulation-eclipse-zero-code-running-lots-cores-10-minutes.html:text/html}
}

@article{humble_integrated_2014,
	title = {An integrated programming and development environment for adiabatic quantum optimization},
	volume = {7},
	issn = {1749-4699},
	url = {http://stacks.iop.org/1749-4699/7/i=1/a=015006},
	doi = {10.1088/1749-4680/7/1/015006},
	abstract = {Adiabatic quantum computing is a promising route to the computational power afforded by quantum information processing. The recent availability of adiabatic hardware has raised challenging questions about how to evaluate adiabatic quantum optimization (AQO) programs. Processor behavior depends on multiple steps to synthesize an adiabatic quantum program, which are each highly tunable. We present an integrated programming and development environment for AQO called Jade Adiabatic Development Environment (JADE) that provides control over all the steps taken during program synthesis. JADE captures the workflow needed to rigorously specify the AQO algorithm while allowing a variety of problem types, programming techniques, and processor configurations. We have also integrated JADE with a quantum simulation engine that enables program profiling using numerical calculation. The computational engine supports plug-ins for simulation methodologies tailored to various metrics and computing resources. We present the design, integration, and deployment of JADE and discuss its potential use for benchmarking AQO programs by the quantum computer science community.},
	language = {en},
	number = {1},
	urldate = {2016-05-25},
	journal = {Comput. Sci. Disc.},
	author = {Humble, T. S. and McCaskey, A. J. and Bennink, R. S. and Billings, J. J. and DʼAzevedo, E. F. and Sullivan, B. D. and Klymko, C. F. and Seddiqi, H.},
	year = {2014},
	pages = {015006},
	file = {IOP Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/UMPIV4KW/Humble et al. - 2014 - An integrated programming and development environm.pdf:application/pdf}
}

@inproceedings{billings_brand_2015,
	address = {Ludwigsburg Germany},
	title = {The brand new {Neutron} {Reflectivity} {Simulator} in {Eclipse} {ICE} and what it took to make it},
	url = {https://www.eclipsecon.org/europe2015/session/brand-new-neutron-reflectivity-simulator-eclipse-ice-and-what-it-took-make-it},
	abstract = {One common method of determining the exact structure of thin films is to put them into a beam of neutrons and see how the neutrons reflect off the surface. Such experiments require significant time and effort at one of a handful of facilities around the world since highly-collimated neutron beams are not generally available at local hardware stores. Simulating the profile of the reflected neutrons can thus greatly accelerate the research by providing insight on the best cases to study and keeping the final experiment focused and efficient.},
	urldate = {2016-05-25},
	booktitle = {{EclipseCon} {Europe} 2015},
	publisher = {Eclipse Foundation},
	author = {Billings, Jay Jay},
	month = jul,
	year = {2015},
	file = {billings_EclipseICE-NR.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/GKD9VKRF/billings_EclipseICE-NR.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/ZJSZWR2F/brand-new-neutron-reflectivity-simulator-eclipse-ice-and-what-it-took-make-it.html:text/html}
}

@article{pannala_multiscale_2015,
	title = {Multiscale modeling and characterization for performance and safety of lithium-ion batteries},
	volume = {118},
	issn = {0021-8979, 1089-7550},
	url = {http://scitation.aip.org/content/aip/journal/jap/118/7/10.1063/1.4927817},
	doi = {10.1063/1.4927817},
	abstract = {Lithium-ion batteries are highly complex electrochemical systems whose performance and safety are governed by coupled nonlinear electrochemical-electrical-thermal-mechanical processes over a range of spatiotemporal scales. Gaining an understanding of the role of these processes as well as development of predictive capabilities for design of better performing batteries requires synergy between theory, modeling, and simulation, and fundamental experimental work to support the models. This paper presents the overview of the work performed by the authors aligned with both experimental and computational efforts. In this paper, we describe a new, open source computational environment for battery simulations with an initial focus on lithium-ion systems but designed to support a variety of model types and formulations. This system has been used to create a three-dimensional cell and battery pack models that explicitly simulate all the battery components (current collectors, electrodes, and separator). The models are used to predict battery performance under normal operations and to study thermal and mechanical safety aspects under adverse conditions. This paper also provides an overview of the experimental techniques to obtain crucial validation data to benchmark the simulations at various scales for performance as well as abuse. We detail some initial validation using characterization experiments such as infrared and neutron imaging and micro-Raman mapping. In addition, we identify opportunities for future integration of theory, modeling, and experiments.},
	number = {7},
	urldate = {2016-05-26},
	journal = {Journal of Applied Physics},
	author = {Pannala, S. and Turner, J. A. and Allu, S. and Elwasif, W. R. and Kalnaus, S. and Simunovic, S. and Kumar, A. and Billings, J. J. and Wang, H. and Nanda, J.},
	month = aug,
	year = {2015},
	keywords = {Batteries, Cathodes, Electrolytes, Lithium, Thermal models},
	pages = {072017},
	file = {Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/39XC9ATU/Pannala et al. - 2015 - Multiscale modeling and characterization for perfo.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/C5PF6JCU/1.html:text/html}
}

@article{brooks_introducing_2016,
	series = {International {Conference} on {Computational} {Science} 2016, {ICCS} 2016, 6-8 {June} 2016, {San} {Diego}, {California}, {USA}},
	title = {Introducing {Triquetrum}, {A} {Possible} {Future} for {Kepler} and {Ptolemy} {II}},
	volume = {80},
	issn = {1877-0509},
	url = {http://www.sciencedirect.com/science/article/pii/S1877050916310377},
	doi = {10.1016/j.procs.2016.05.546},
	abstract = {Triquetrum is an open platform for managing and executing scientific workflows that is under development as an Eclipse project. Both Triquetrum and Kepler use Ptolemy II as their execution engine. Triquetrum presents opportunities and risks for the Kepler community. The opportunities include a possibly larger community for interaction and a path for Kepler to move from Kepler's one-off ant-based build environment towards a more common OSGi-based environment and a way to maintain a stable Ptolemy II core. The risks include the fact that Triquetrum is a fork of Ptolemy II that would result in package name changes and other possible changes. In addition, Triquetrum is licensed under the Eclipse Public License v1.0, which includes a patent clause that could conflict with the University of California patent clause. This paper describes these opportunities and risks.},
	urldate = {2016-06-23},
	journal = {Procedia Computer Science},
	author = {Brooks, Christopher and Billings, Jay Jay},
	year = {2016},
	keywords = {Eclipse, Eclipse Public License, Kepler, Ptolemy II, Triquetrum, Visual Programming Systems, Workflow Management Systems},
	pages = {2449--2454},
	file = {ScienceDirect Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/HDJVZSWQ/Brooks and Billings - 2016 - Introducing Triquetrum, A Possible Future for Kepl.pdf:application/pdf;ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/FPRNXFFC/S1877050916310377.html:text/html}
}

@misc{billings_workflows_2016,
	title = {Workflows for {Rocket} {Scientists}/{Dummies}},
	url = {http://www.csm.ornl.gov/SOS20/agenda.html},
	urldate = {2016-08-28},
	author = {Billings, Jay Jay},
	month = mar,
	year = {2016},
	file = {billings_SOS20_20160323.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/B2GBHI2X/billings_SOS20_20160323.pdf:application/pdf;SOS20:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/EUD6H2MW/agenda.html:text/html}
}

@article{jha_building_2016,
	title = {A {Building} {Blocks} {Approach} towards {Domain} {Specific} {Workflow} {Systems}?},
	url = {http://arxiv.org/abs/1609.03484},
	abstract = {This paper makes the case for a fresh perspective on workflow-systems and, in doing so, argues for a building blocks approach to the design of workflow-systems. We outline a description of the building block approach and define their properties. We discuss RADICAL-Cybertools as an implementation of the building block concept, showing how they have been designed and developed in accordance to the building blocks method. Two use cases describe how {\textbackslash}rct building blocks have been used to develop and integrate scientific workflow systems illustrating the applicability and potential of software building blocks. In doing so we have begun an investigation of an alternative and conceptual approach to thinking the design and implementation of scientific workflow-systems.},
	urldate = {2016-12-14},
	journal = {arXiv:1609.03484 [cs]},
	author = {Jha, Shantenu and Turilli, Matteo},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.03484},
	keywords = {Computer Science - Software Engineering},
	file = {arXiv\:1609.03484 PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/KMW7UDH2/Jha and Turilli - 2016 - A Building Blocks Approach towards Domain Specific.pdf:application/pdf;arXiv.org Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/SJ77RI2V/1609.html:text/html}
}

@article{turilli_comprehensive_2015,
	title = {A {Comprehensive} {Perspective} on {Pilot}-{Job} {Systems}},
	url = {http://arxiv.org/abs/1508.04180},
	abstract = {Pilot-Job systems play an important role in supporting distributed scientific computing. They are used to consume more than 700 million CPU hours a year by the Open Science Grid communities, and by processing up to 1 million jobs a day for the ATLAS experiment on the Worldwide LHC Computing Grid. With the increasing importance of task-level parallelism in high-performance computing, Pilot-Job systems are also witnessing an adoption beyond traditional domains. Notwithstanding the growing impact on scientific research, there is no agreement upon a definition of Pilot-Job system and no clear understanding of the underlying abstraction and paradigm. Pilot-Job implementations have proliferated with no shared best practices or open interfaces and little interoperability. Ultimately, this is hindering the realization of the full impact of Pilot-Jobs by limiting their robustness, portability, and maintainability. This paper offers a comprehensive analysis of Pilot-Job systems critically assessing their motivations, evolution, properties, and implementation. The three main contributions of this paper are: (i) an analysis of the motivations and evolution of Pilot-Job systems; (ii) an outline of the Pilot abstraction, its distinguishing logical components and functionalities, its terminology, and its architecture pattern; and (iii) the description of core and auxiliary properties of Pilot-Jobs systems and the analysis of seven exemplar Pilot-Job implementations. Together, these contributions illustrate the Pilot paradigm, its generality, and how it helps to address some challenges in distributed scientific computing.},
	urldate = {2016-12-14},
	journal = {arXiv:1508.04180 [cs]},
	author = {Turilli, Matteo and Santcroos, Mark and Jha, Shantenu},
	month = aug,
	year = {2015},
	note = {arXiv: 1508.04180},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Software Engineering, 68Nxx},
	file = {arXiv\:1508.04180 PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/K9JPBEIU/Turilli et al. - 2015 - A Comprehensive Perspective on Pilot-Job Systems.pdf:application/pdf;arXiv.org Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/AS6VMSIH/1508.html:text/html}
}

@article{yu_rutgers_2007,
	title = {The {Rutgers} {Workflow} {Management} {System}:  {Migrating} a {Digital} {Object} {Management} {Utility} to {Open} {Source}},
	issn = {1940-5758},
	shorttitle = {The {Rutgers} {Workflow} {Management} {System}},
	url = {http://journal.code4lib.org/articles/25},
	abstract = {This article examines the development, architecture, and future plans for the Workflow Management System, software developed by Rutgers University Libraries (RUL) to create and catalog digital objects for repository ingest and access. The Workflow Management System (WMS) was created as a front-end utility for the Fedora open source repository platform and a vehicle for a flexible, extensible metadata architecture, to serve the information needs of a large university and its collaborators. The next phase of development for the WMS shifted to a re-engineering of the WMS as an open source application. This paper discusses the design and architecture of the WMS, its re-engineering for open source release, remaining issues to be addressed before application release, and future development plans for the WMS.},
	number = {1},
	urldate = {2016-12-14},
	journal = {The Code4Lib Journal},
	author = {Yu, Grace Agnew \& Yang},
	month = dec,
	year = {2007},
	file = {Code4Lib Journal Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/X65DT7JT/25.html:text/html}
}

@article{rosemann_evaluation_1998,
	title = {Evaluation of {Workflow} {Management} {Systems} - {A} {Meta} {Model} {Approach}},
	volume = {6},
	copyright = {Copyright (c) 1969 Michael Rosemann, Michael zur Muehlen},
	issn = {1449-8618},
	url = {http://journal.acs.org.au/index.php/ajis/article/view/322},
	doi = {10.3127/ajis.v6i1.322},
	abstract = {The automated enactment of processes through the use of workflow management systems enables the outsourcing of the
control flow from application systems. By now a large number of systems, that follow different workflow paradigms, are
available. This leads to the problem of selecting the appropriate workflow management system for a given situation. In this paper we outline the benefits of a meta model approach for the evaluation and comparison of different workflow management systems. After a general introduction on the topic of meta modeling the meta models of the workflow management systems WorkParty (Siemens Nixdorf) and FlowMark (IBM) are compared as an example. These product specific meta models can be generalized to meta reference models, which helps to specify a workflow methodology. Exemplary, an organisational reference meta model is presented, which helps users in specifying their requirements for a workflow management system.},
	language = {en},
	number = {1},
	urldate = {2016-12-14},
	journal = {Australasian Journal of Information Systems},
	author = {Rosemann, Michael and Muehlen, Michael zur},
	year = {1998},
	keywords = {workflow management, WorkParty, outsourcing, FlowMark, model},
	file = {Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/UMV67PC8/Rosemann and Muehlen - 1998 - Evaluation of Workflow Management Systems - A Meta.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/EVB5ZDGV/322.html:text/html}
}

@book{allemang_semantic_2008,
	address = {Amsterdam},
	title = {Semantic web for the working ontologist: modeling in {RDF}, {RDFS} and {OWL}},
	isbn = {978-0-12-373556-0},
	shorttitle = {Semantic web for the working ontologist},
	language = {eng},
	publisher = {Morgan Kaufmann/Elsevier},
	author = {Allemang, Dean and Hendler, James A.},
	year = {2008},
	note = {OCLC: 184925396},
	keywords = {Semantic Web, Web site development, Metadata},
	annote = {Literaturverz. S. 317 - 320},
	file = {Ontologist.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/VVTDH84R/Ontologist.pdf:application/pdf}
}

@misc{vaadin_docs_2016,
	title = {Docs - vaadin.com {Creating} and {Running} a {Project} in {Eclipse} · {Vaadin}},
	url = {https://vaadin.com/docs},
	urldate = {2016-12-15},
	journal = {vaadin.com},
	author = {Vaadin},
	year = {2016},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/9UBCVJR9/getting-started-first-project.html:text/html}
}

@misc{vaadin_working_2016,
	title = {A working {Vaadin}, {Equinox}, {Jetty} application with {Eclipse} - {Wiki}},
	url = {https://vaadin.com/wiki},
	abstract = {For the last two weeks I\&\#39;ve been trying to develop a simple Vaadin application that could work as a stand alone OSGI bundle since Tomcat does not have support for OSGI. You could...},
	urldate = {2016-12-15},
	journal = {vaadin.com},
	author = {Vaadin},
	year = {2016},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/AC5SHRWM/wiki.html:text/html}
}

@misc{jekyll_build_2014,
	title = {Build {A} {Blog} {With} {Jekyll} {And} {GitHub} {Pages}},
	url = {https://www.smashingmagazine.com/2014/08/build-blog-jekyll-github-pages/},
	abstract = {Jekyll is a website generator that’s designed for building minimal, static blogs to be hosted on GitHub Pages. This article shows how to set it up.},
	urldate = {2016-12-19},
	journal = {Smashing Magazine},
	author = {Jekyll},
	month = aug,
	year = {2014},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/IWNAFWZ5/build-blog-jekyll-github-pages.html:text/html}
}

@inproceedings{barker_scientific_2007,
	title = {Scientific {Workflow}: {A} {Survey} and {Research} {Directions}},
	shorttitle = {Scientific {Workflow}},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-68111-3_78},
	abstract = {Workflow technologies are emerging as the dominant approach to coordinate groups of distributed services. However with a space filled with competing specifications, standards and frameworks from multiple domains, choosing the right tool for the job is not always a straightforward task. Researchers are often unaware of the range of technology that already exists and focus on implementing yet another proprietary workflow system. As an antidote to this common problem, this paper presents a concise survey of existing workflow technology from the business and scientific domain and makes a number of key suggestions towards the future development of scientific workflow systems.},
	language = {en},
	urldate = {2016-12-20},
	booktitle = {Parallel {Processing} and {Applied} {Mathematics}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Barker, Adam and Hemert, Jano van},
	month = sep,
	year = {2007},
	doi = {10.1007/978-3-540-68111-3_78},
	pages = {746--753},
	file = {Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/KS8U5A5X/Barker and Hemert - 2007 - Scientific Workflow A Survey and Research Directi.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/NHIJMFIX/978-3-540-68111-3_78.html:text/html}
}

@article{tolosana-calasanz_enforcing_2012,
	series = {{JCSS} {Special} {Issue}: {Cloud} {Computing} 2011},
	title = {Enforcing {QoS} in scientific workflow systems enacted over {Cloud} infrastructures},
	volume = {78},
	issn = {0022-0000},
	url = {http://www.sciencedirect.com/science/article/pii/S0022000011001607},
	doi = {10.1016/j.jcss.2011.12.015},
	abstract = {The ability to support Quality of Service (QoS) constraints is an important requirement in some scientific applications. With the increasing use of Cloud computing infrastructures, where access to resources is shared, dynamic and provisioned on-demand, identifying how QoS constraints can be supported becomes an important challenge. However, access to dedicated resources is often not possible in existing Cloud deployments and limited QoS guarantees are provided by many commercial providers (often restricted to error rate and availability, rather than particular QoS metrics such as latency or access time). We propose a workflow system architecture which enforces QoS for the simultaneous execution of multiple scientific workflows over a shared infrastructure (such as a Cloud environment). Our approach involves multiple pipeline workflow instances, with each instance having its own QoS requirements. These workflows are composed of a number of stages, with each stage being mapped to one or more physical resources. A stage involves a combination of data access, computation and data transfer capability. A token bucket-based data throttling framework is embedded into the workflow system architecture. Each workflow instance stage regulates the amount of data that is injected into the shared resources, allowing for bursts of data to be injected while at the same time providing isolation of workflow streams. We demonstrate our approach by using the Montage workflow, and develop a Reference net model of the workflow.},
	number = {5},
	urldate = {2016-12-20},
	journal = {Journal of Computer and System Sciences},
	author = {Tolosana-Calasanz, Rafael and Bañares, José Ángel and Pham, Congduc and Rana, Omer F.},
	month = sep,
	year = {2012},
	keywords = {QoS, Petri nets, scientific workflows, Cloud computing},
	pages = {1300--1315},
	file = {ScienceDirect Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/HSW3FTJQ/Tolosana-Calasanz et al. - 2012 - Enforcing QoS in scientific workflow systems enact.pdf:application/pdf;ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/9WKRFSNV/S0022000011001607.html:text/html}
}

@article{chen_temporal_2011,
	title = {Temporal {Dependency}-based {Checkpoint} {Selection} for {Dynamic} {Verification} of {Temporal} {Constraints} in {Scientific} {Workflow} {Systems}},
	volume = {20},
	issn = {1049-331X},
	url = {http://doi.acm.org/10.1145/2000791.2000793},
	doi = {10.1145/2000791.2000793},
	abstract = {In a scientific workflow system, a checkpoint selection strategy is used to select checkpoints along scientific workflow execution for verifying temporal constraints so that we can identify any temporal violations and handle them in time in order to ensure overall temporal correctness of the execution that is often essential for the usefulness of execution results. The problem of existing representative strategies is that they do not differentiate temporal constraints as, once a checkpoint is selected, they verify all temporal constraints. However, such a checkpoint does not need to be taken for those constraints whose consistency can be deduced from others. The corresponding verification of such constraints is consequently unnecessary and can severely impact overall temporal verification efficiency while the efficiency determines whether temporal violations can be identified quickly for handling in time. To address the problem, in this article, we develop a new temporal-dependency based checkpoint selection strategy which can select checkpoints in accordance with different temporal constraints. With our strategy, the corresponding unnecessary verification can be avoided. The comparison and experimental simulation further demonstrate that our new strategy can improve the efficiency of overall temporal verification significantly over the existing representative strategies.},
	number = {3},
	urldate = {2016-12-20},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Chen, Jinjun and Yang, Yun},
	month = aug,
	year = {2011},
	keywords = {temporal constraints, checkpoint selection, temporal verification, scientific workflows},
	pages = {9:1--9:23},
	file = {ACM Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/HR7CUF2K/Chen and Yang - 2011 - Temporal Dependency-based Checkpoint Selection for.pdf:application/pdf}
}

@article{juve_scientific_2009,
	title = {Scientific {Workflow} {Applications} on {Amazon} {EC}2},
	url = {http://arxiv.org/abs/1005.2718},
	doi = {10.1109/ESCIW.2009.5408002},
	abstract = {The proliferation of commercial cloud computing providers has generated significant interest in the scientific computing community. Much recent research has attempted to determine the benefits and drawbacks of cloud computing for scientific applications. Although clouds have many attractive features, such as virtualization, on-demand provisioning, and "pay as you go" usage-based pricing, it is not clear whether they are able to deliver the performance required for scientific applications at a reasonable price. In this paper we examine the performance and cost of clouds from the perspective of scientific workflow applications. We use three characteristic workflows to compare the performance of a commercial cloud with that of a typical HPC system, and we analyze the various costs associated with running those workflows in the cloud. We find that the performance of clouds is not unreasonable given the hardware resources provided, and that performance comparable to HPC systems can be achieved given similar resources. We also find that the cost of running workflows on a commercial cloud can be reduced by storing data in the cloud rather than transferring it from outside.},
	urldate = {2016-12-20},
	journal = {arXiv:1005.2718 [astro-ph]},
	author = {Juve, Gideon and Deelman, Ewa and Vahi, Karan and Mehta, Gaurang and Berriman, Bruce and Berman, Benjamin P. and Maechling, Phil},
	month = dec,
	year = {2009},
	note = {arXiv: 1005.2718},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Astrophysics - Instrumentation and Methods for Astrophysics},
	pages = {59--66},
	file = {arXiv\:1005.2718 PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/VSQFV9XA/Juve et al. - 2009 - Scientific Workflow Applications on Amazon EC2.pdf:application/pdf;arXiv.org Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/M4GW9V87/1005.html:text/html}
}

@book{wainer_scientific_1997,
	title = {Scientific workflow systems},
	abstract = {This paper will discuss some of the basic assumptions behind office work and  scientific work, and show that workflow systems for these two endeavors should  have different functionalities. In particular we discuss the idea that data management  and management of workflow models are the most important aspects of  scientific workflows.},
	author = {Wainer, Jacques and Weske, Mathias and Vossen, Gottfried and Medeiros, Claudia Bauzer},
	year = {1997},
	file = {Citeseer - Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/UC6KVP2F/Wainer et al. - 1997 - Scientific workflow systems.pdf:application/pdf;Citeseer - Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/DZENGKJU/summary.html:text/html}
}

@incollection{weske_business_2012,
	title = {Business {Process} {Management} {Architectures}},
	copyright = {©2012 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-28615-5 978-3-642-28616-2},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-28616-2_7},
	abstract = {BPM architectures are in the centre of Chapter 7, starting from the WfMC Architecture and proceeding towards service oriented architectures and architectures for flexible workflow management. In particular, an architecture that allows to dynamically modify running workflow instances based on an object-oriented approach is introduced. Web services and their composition are sketched, describing the core concepts of the XML-based service composition language WS-BPEL. Advanced service composition based on semantic concepts are sketched, and case handling is introduced as a technique for flexible process enactment based on data dependencies rather than process structures.},
	language = {en},
	urldate = {2016-12-20},
	booktitle = {Business {Process} {Management}},
	publisher = {Springer Berlin Heidelberg},
	author = {Weske, Mathias},
	year = {2012},
	doi = {10.1007/978-3-642-28616-2_7},
	keywords = {Computer Appl. in Administrative Data Processing, Information Systems Applications (incl. Internet), Software Engineering, IT in Business, e-Commerce/e-business},
	pages = {333--371},
	file = {Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/U69IB3PZ/Weske - 2012 - Business Process Management Architectures.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/XITST5VF/978-3-642-28616-2_7.html:text/html}
}

@article{chiu_meta_1999,
	series = {Meta-{Modelling} and {Methodology} {Engineering}},
	title = {A meta modeling approach to workflow management systems supporting exception handling},
	volume = {24},
	issn = {0306-4379},
	url = {http://www.sciencedirect.com/science/article/pii/S0306437999000101},
	doi = {10.1016/S0306-4379(99)00010-1},
	abstract = {Workflow Management Systems (WFMSs) facilitate the definition of structure and decomposition of business processes and assists in management of coordinating, scheduling, executing and monitoring of such activities. Most of the current WFMSs are built on traditional relational database systems and/or using an object-oriented database system for storing the definition and run time data about the workflows. However, a WFMS requires advanced modeling functionalities to support adaptive features, such as on-line exception handling. This article describes our advanced meta-modeling approach using various enabling technologies (such as object orientation, roles, rules, active capabilities) supported by an integrated environment, the ADOME, as a solid basis for a flexible WFMS involving dynamic match making, migrating workflows and exception handling.},
	number = {2},
	urldate = {2016-12-20},
	journal = {Information Systems},
	author = {Chiu, Dickson K. W. and Li, Qing and Karlapalem, Kamalakar},
	month = apr,
	year = {1999},
	keywords = {workflow management, Match-Making, Object-Orientation, Meta-modeling, Workflow Evolution, Exception Handling},
	pages = {159--184},
	file = {ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/WUQZNVQ5/S0306437999000101.html:text/html}
}

@book{aalst_workflow_2004,
	title = {Workflow {Management}: {Models}, {Methods}, and {Systems}},
	isbn = {978-0-262-72046-5},
	shorttitle = {Workflow {Management}},
	abstract = {This book offers a comprehensive introduction to workflow management, the management of business processes with information technology. By defining, analyzing, and redesigning an organization's resources and operations, workflow management systems ensure that the right information reaches the right person or computer application at the right time. The book provides a basic overview of workflow terminology and organization, as well as detailed coverage of workflow modeling with Petri nets. Because Petri nets make definitions easier to understand for nonexperts, they facilitate communication between designers and users. The book includes a chapter of case studies, review exercises, and a glossary. A special Web site developed by the authors, www.workflowcourse.com, features animation, interactive examples, lecture materials, exercises and solutions, relevant links, and other valuable resources for the classroom.},
	language = {en},
	publisher = {MIT Press},
	author = {Aalst, Wil van der and Hee, Kees Max van},
	year = {2004},
	keywords = {Business \& Economics / Management}
}

@book{taylor_workflows_2014,
	title = {Workflows for e-{Science}: {Scientific} {Workflows} for {Grids}},
	isbn = {978-1-84996-619-1},
	shorttitle = {Workflows for e-{Science}},
	abstract = {This is a timely book presenting an overview of the current state-of-the-art within established projects, presenting many different aspects of workflow from users to tool builders. It provides an overview of active research, from a number of different perspectives. It includes theoretical aspects of workflow and deals with workflow for e-Science as opposed to e-Commerce. The topics covered will be of interest to a wide range of practitioners.},
	publisher = {Springer Publishing Company, Incorporated},
	author = {Taylor, Ian J. and Deelman, Ewa and Gannon, Dennis B. and Shields, Matthew},
	year = {2014}
}

@inproceedings{mandal_integrating_2007,
	address = {New York, NY, USA},
	series = {{WORKS} '07},
	title = {Integrating {Existing} {Scientific} {Workflow} {Systems}: {The} {Kepler}/{Pegasus} {Example}},
	isbn = {978-1-59593-715-5},
	shorttitle = {Integrating {Existing} {Scientific} {Workflow} {Systems}},
	url = {http://doi.acm.org/10.1145/1273360.1273365},
	doi = {10.1145/1273360.1273365},
	abstract = {Scientific workflows have become an important tool used by scientists to conduct large-scale analysis in distributed environments. Today thereare a variety of workflow systems that provide an often disjoint set of capabilities and expose different workflow modeling semantics to the users. In this paper we examine the possibility of integrating two well-known workflow systems Kepler and Pegasus and examine the opportunities and challenges presented by such an integration. We illustrate the combined system on a workflow used as a basis of a provenance challenge.},
	urldate = {2016-12-20},
	booktitle = {Proceedings of the 2nd {Workshop} on {Workflows} in {Support} of {Large}-scale {Science}},
	publisher = {ACM},
	author = {Mandal, Nandita and Deelman, Ewa and Mehta, Gaurang and Su, Mei-Hui and Vahi, Karan},
	year = {2007},
	keywords = {programming models, user interfaces, scientific workflows},
	pages = {21--28},
	file = {ACM Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/NHBRSAGS/Mandal et al. - 2007 - Integrating Existing Scientific Workflow Systems .pdf:application/pdf}
}

@inproceedings{han_taxonomy_1998,
	title = {A taxonomy of adaptive workflow management},
	url = {https://www.researchgate.net/profile/Amit_Sheth/publication/228729962_A_taxonomy_of_adaptive_workflow_management/links/02bfe5105a211e3991000000.pdf},
	urldate = {2016-12-20},
	booktitle = {Workshop of the 1998 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work}},
	author = {Han, Yanbo and Sheth, Amit and Bussler, Christoph},
	year = {1998},
	file = {A_taxonomy_of_adaptive_workflow_management.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/9A2AA6BJ/A_taxonomy_of_adaptive_workflow_management.pdf:application/pdf}
}

@article{davidson_provenance_2007,
	title = {Provenance in {Scientific} {Workflow} {Systems}.},
	volume = {30},
	url = {ftp://131.107.65.22/pub/debull/A07dec/susan.pdf},
	number = {4},
	urldate = {2016-12-20},
	journal = {IEEE Data Eng. Bull.},
	author = {Davidson, Susan B. and Boulakia, Sarah Cohen and Eyal, Anat and Ludäscher, Bertram and McPhillips, Timothy M. and Bowers, Shawn and Anand, Manish Kumar and Freire, Juliana},
	year = {2007},
	pages = {44--50},
	file = {C\:\\DEBull\\2007\\December\\SUSAN\\DataEngV4.dvi - susan.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/EVDTEXAR/susan.pdf:application/pdf}
}

@article{yu_taxonomy_2005,
	title = {A {Taxonomy} of {Workflow} {Management} {Systems} for {Grid} {Computing}},
	volume = {3},
	issn = {1570-7873, 1572-9184},
	url = {http://link.springer.com/article/10.1007/s10723-005-9010-8},
	doi = {10.1007/s10723-005-9010-8},
	abstract = {With the advent of Grid and application technologies, scientists and engineers are building more and more complex applications to manage and process large data sets, and execute scientific experiments on distributed resources. Such application scenarios require means for composing and executing complex workflows. Therefore, many efforts have been made towards the development of workflow management systems for Grid computing. In this paper, we propose a taxonomy that characterizes and classifies various approaches for building and executing workflows on Grids. We also survey several representative Grid workflow systems developed by various projects world-wide to demonstrate the comprehensiveness of the taxonomy. The taxonomy not only highlights the design and engineering similarities and differences of state-of-the-art in Grid workflow systems, but also identifies the areas that need further research.},
	language = {en},
	number = {3-4},
	urldate = {2016-12-20},
	journal = {J Grid Computing},
	author = {Yu, Jia and Buyya, Rajkumar},
	month = sep,
	year = {2005},
	pages = {171--200},
	file = {Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/HR9KQA46/Yu and Buyya - 2005 - A Taxonomy of Workflow Management Systems for Grid.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/77XI4GDC/s10723-005-9010-8.html:text/html}
}

@article{green_integrated_2000,
	series = {The 11th {International} {Conference} on {Advanced} {Information} {System} {Engineering}},
	title = {Integrated process modeling: {An} ontological evaluation},
	volume = {25},
	issn = {0306-4379},
	shorttitle = {Integrated process modeling},
	url = {http://www.sciencedirect.com/science/article/pii/S0306437900000107},
	doi = {10.1016/S0306-4379(00)00010-7},
	abstract = {Process modeling has gained prominence in the information systems modeling area due to its focus on business processes and its usefulness in such business improvement methodologies as Total Quality Management, Business Process Reengineering, and Workflow Management. However, process modeling techniques are not without their criticisms [13]. This paper proposes and uses the Bunge-Wand-Weber (BWW) representation model to analyze the five views — process, data, function, organization and output — provided in the Architecture of Integrated Information Systems (ARIS) popularized by Scheer [39, 40, 41]. The BWW representation model attempts to provide a theoretical base on which to evaluate and thus contribute to the improvement of information systems modeling techniques. The analysis conducted in this paper prompts some propositions. It confirms that the process view alone is not sufficient to model all the real-world constructs required. Some other symbols or views are needed to overcome these deficiencies. However, even when considering all five views in combination, problems may arise in representing all potentially required business rules, specifying the scope and boundaries of the system under consideration, and employing a “top-down” approach to analysis and design. Further work from this study will involve the operationalization of these propositions and their empirical testing in the field.},
	number = {2},
	urldate = {2016-12-20},
	journal = {Information Systems},
	author = {Green, Peter and Rosemann, Michael},
	month = apr,
	year = {2000},
	keywords = {Architecture of Integrated Information Systems, Ontology, Process Modeling},
	pages = {73--87},
	file = {ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/U59CCBWS/S0306437900000107.html:text/html}
}

@inproceedings{medina-mora_action_1992,
	address = {New York, NY, USA},
	series = {{CSCW} '92},
	title = {The {Action} {Workflow} {Approach} to {Workflow} {Management} {Technology}},
	isbn = {978-0-89791-542-7},
	url = {http://doi.acm.org/10.1145/143457.143530},
	doi = {10.1145/143457.143530},
	urldate = {2016-12-20},
	booktitle = {Proceedings of the 1992 {ACM} {Conference} on {Computer}-supported {Cooperative} {Work}},
	publisher = {ACM},
	author = {Medina-Mora, Raul and Winograd, Terry and Flores, Rodrigo and Flores, Fernando},
	year = {1992},
	keywords = {workflow, coordinator, Action Workflow, coordination},
	pages = {281--288}
}

@article{abramson_embedding_2010,
	title = {Embedding optimization in computational science workflows},
	volume = {1},
	issn = {1877-7503},
	url = {http://www.sciencedirect.com/science/article/pii/S1877750310000165},
	doi = {10.1016/j.jocs.2010.04.002},
	abstract = {Workflows support the automation of scientific processes, providing mechanisms that underpin modern computational science. They facilitate access to remote instruments, databases and parallel and distributed computers. Importantly, they allow software pipelines that perform multiple complex simulations (leveraging distributed platforms), with one simulation driving another. Such an environment is ideal for computational science experiments that require the evaluation of a range of different scenarios “in silico” in an attempt to find ones that optimize a particular outcome. However, in general, existing workflow tools do not incorporate optimization algorithms, and thus whilst users can specify simulation pipelines, they need to invoke the workflow as a stand-alone computation within an external optimization tool. Moreover, many existing workflow engines do not leverage parallel and distributed computers, making them unsuitable for executing computational science simulations. To solve this problem, we have developed a methodology for integrating optimization algorithms directly into workflows. We implement a range of generic actors for an existing workflow system called Kepler, and discuss how they can be combined in flexible ways to support various different design strategies. We illustrate the system by applying it to an existing bio-engineering design problem running on a Grid of distributed clusters.},
	number = {1},
	urldate = {2016-12-20},
	journal = {Journal of Computational Science},
	author = {Abramson, David and Bethwaite, Blair and Enticott, Colin and Garic, Slavisa and Peachey, Tom and Michailova, Anushka and Amirriazi, Saleh},
	month = may,
	year = {2010},
	keywords = {Workflows, Cardiac models, Grid computing, Design optimization},
	pages = {41--47},
	file = {ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/W7NR9F8V/S1877750310000165.html:text/html}
}

@article{ludascher_scientific_2006,
	title = {Scientific workflow management and the {Kepler} system},
	volume = {18},
	issn = {1532-0634},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/cpe.994/abstract},
	doi = {10.1002/cpe.994},
	abstract = {Many scientific disciplines are now data and information driven, and new scientific knowledge is often gained by scientists putting together data analysis and knowledge discovery ‘pipelines’. A related trend is that more and more scientific communities realize the benefits of sharing their data and computational services, and are thus contributing to a distributed data and computational community infrastructure (a.k.a. ‘the Grid’). However, this infrastructure is only a means to an end and ideally scientists should not be too concerned with its existence. The goal is for scientists to focus on development and use of what we call scientific workflows. These are networks of analytical steps that may involve, e.g., database access and querying steps, data analysis and mining steps, and many other steps including computationally intensive jobs on high-performance cluster computers. In this paper we describe characteristics of and requirements for scientific workflows as identified in a number of our application projects. We then elaborate on Kepler, a particular scientific workflow system, currently under development across a number of scientific data management projects. We describe some key features of Kepler and its underlying Ptolemy II system, planned extensions, and areas of future research. Kepler is a community-driven, open source project, and we always welcome related projects and new contributors to join. Copyright © 2005 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {10},
	urldate = {2016-12-20},
	journal = {Concurrency Computat.: Pract. Exper.},
	author = {Ludäscher, Bertram and Altintas, Ilkay and Berkley, Chad and Higgins, Dan and Jaeger, Efrat and Jones, Matthew and Lee, Edward A. and Tao, Jing and Zhao, Yang},
	month = aug,
	year = {2006},
	keywords = {scientific data management, problem-solving environments, scientific workflows, Grid workflows, dataflow networks},
	pages = {1039--1065},
	file = {Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/WB4GUNBI/Ludäscher et al. - 2006 - Scientific workflow management and the Kepler syst.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/EJ3ZXKF5/abstract.html:text/html}
}

@article{yu_taxonomy_2005-1,
	title = {A {Taxonomy} of {Workflow} {Management} {Systems} for {Grid} {Computing}},
	url = {http://arxiv.org/abs/cs/0503025},
	abstract = {With the advent of Grid and application technologies, scientists and engineers are building more and more complex applications to manage and process large data sets, and execute scientific experiments on distributed resources. Such application scenarios require means for composing and executing complex workflows. Therefore, many efforts have been made towards the development of workflow management systems for Grid computing. In this paper, we propose a taxonomy that characterizes and classifies various approaches for building and executing workflows on Grids. We also survey several representative Grid workflow systems developed by various projects world-wide to demonstrate the comprehensiveness of the taxonomy. The taxonomy not only highlights the design and engineering similarities and differences of state-of-the-art in Grid workflow systems, but also identifies the areas that need further research.},
	urldate = {2016-12-20},
	journal = {arXiv:cs/0503025},
	author = {Yu, Jia and Buyya, Rajkumar},
	month = mar,
	year = {2005},
	note = {arXiv: cs/0503025},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, D.1},
	annote = {Comment: 29 pages, 15 figures},
	file = {arXiv\:cs/0503025 PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/FU4Z5SQW/Yu and Buyya - 2005 - A Taxonomy of Workflow Management Systems for Grid.pdf:application/pdf;arXiv.org Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/5MBD6NIE/0503025.html:text/html}
}

@article{liu_we_2014,
	title = {Do {We} {Need} to {Handle} {Every} {Temporal} {Violation} in {Scientific} {Workflow} {Systems}?},
	volume = {23},
	issn = {1049-331X},
	url = {http://doi.acm.org/10.1145/2559938},
	doi = {10.1145/2559938},
	abstract = {Scientific processes are usually time constrained with overall deadlines and local milestones. In scientific workflow systems, due to the dynamic nature of the underlying computing infrastructures such as grid and cloud, execution delays often take place and result in a large number of temporal violations. Since temporal violation handling is expensive in terms of both monetary costs and time overheads, an essential question aroused is “do we need to handle every temporal violation in scientific workflow systems?” The answer would be “true” according to existing works on workflow temporal management which adopt the philosophy similar to the handling of functional exceptions, that is, every temporal violation should be handled whenever it is detected. However, based on our observation, the phenomenon of self-recovery where execution delays can be automatically compensated for by the saved execution time of subsequent workflow activities has been entirely overlooked. Therefore, considering the nonfunctional nature of temporal violations, our answer is “not necessarily true.” To take advantage of self-recovery, this article proposes a novel adaptive temporal violation handling point selection strategy where this phenomenon is effectively utilised to avoid unnecessary temporal violation handling. Based on simulations of both real-world scientific workflows and randomly generated test cases, the experimental results demonstrate that our strategy can significantly reduce the cost on temporal violation handling by over 96\% while maintaining extreme low violation rate under normal circumstances.},
	number = {1},
	urldate = {2016-12-20},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Liu, Xiao and Yang, Yun and Yuan, Dong and Chen, Jinjun},
	month = feb,
	year = {2014},
	keywords = {quality of service, temporal constraints, temporal verification, scientific workflows, violation handling point selection},
	pages = {5:1--5:34},
	file = {ACM Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/9FQK3GJE/Liu et al. - 2014 - Do We Need to Handle Every Temporal Violation in S.pdf:application/pdf}
}

@inproceedings{altintas_provenance_2006,
	title = {Provenance {Collection} {Support} in the {Kepler} {Scientific} {Workflow} {System}},
	url = {http://link.springer.com/chapter/10.1007/11890850_14},
	abstract = {In many data-driven applications, analysis needs to be performed on scientific information obtained from several sources and generated by computations on distributed resources. Systematic analysis of this scientific information unleashes a growing need for automated data-driven applications that also can keep track of the provenance of the data and processes with little user interaction and overhead. Such data analysis can be facilitated by the recent advancements in scientific workflow systems. A major profit when using scientific workflow systems is the ability to make provenance collection a part of the workflow. Specifically, provenance should include not only the standard data lineage information but also information about the context in which the workflow was used, execution that processed the data, and the evolution of the workflow design. In this paper we describe a complete framework for data and process provenance in the Kepler Scientific Workflow System. We outline the requirements and issues related to data and workflow provenance in a multi-disciplinary workflow system and introduce how generic provenance capture can be facilitated in Kepler’s actor-oriented workflow environment. We also describe the usage of the stored provenance information for efficient rerun of scientific workflows.},
	language = {en},
	urldate = {2016-12-20},
	booktitle = {Provenance and {Annotation} of {Data}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Altintas, Ilkay and Barney, Oscar and Jaeger-Frank, Efrat},
	month = may,
	year = {2006},
	doi = {10.1007/11890850_14},
	pages = {118--132},
	file = {Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/V5SRUKV7/Altintas et al. - 2006 - Provenance Collection Support in the Kepler Scient.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/HKMDRS99/11890850_14.html:text/html}
}

@article{liu_case_2005,
	title = {A case study of an inter-enterprise workflow-supported supply chain management system},
	volume = {42},
	issn = {0378-7206},
	url = {http://www.sciencedirect.com/science/article/pii/S037872060400045X},
	doi = {10.1016/j.im.2004.01.010},
	abstract = {Doing business over the Internet is cheap and convenient. This enlarges the view of enterprises and gives them an opportunity to select their partners. To support business-to-business operations, an information system (IS) with an embedded workflow management component is needed. The inherent characteristics of such a system makes it suitable to implement cross-organization management. Nowadays, however, these system additions are not common. When developing a supply chain management (SCM) system for a large motorcycle corporation in China, we had to construct an inter-enterprise architecture using the internet. The main part of this is a workflow-supported inner supply chain system and an integrated interface. In it, the business processes are defined and executed by the supply chain management system. The independent inner systems are connected by the integrated interface into a large, global, supply chain manage system to management business processes across the independent enterprises. This paper presents the system design and implementation and discusses our experiences and lessons learned.},
	number = {3},
	urldate = {2016-12-20},
	journal = {Information \& Management},
	author = {Liu, Jianxun and Zhang, Shensheng and Hu, Jinming},
	month = mar,
	year = {2005},
	keywords = {workflow management, Electronic commerce, Interoperability, Supply chain, Agent},
	pages = {441--454},
	file = {ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/PD5TJVH6/S037872060400045X.html:text/html}
}

@article{warr_scientific_2012,
	title = {Scientific workflow systems: {Pipeline} {Pilot} and {KNIME}},
	volume = {26},
	issn = {0920-654X, 1573-4951},
	shorttitle = {Scientific workflow systems},
	url = {http://link.springer.com/article/10.1007/s10822-012-9577-7},
	doi = {10.1007/s10822-012-9577-7},
	language = {en},
	number = {7},
	urldate = {2016-12-20},
	journal = {J Comput Aided Mol Des},
	author = {Warr, Wendy A.},
	month = jul,
	year = {2012},
	pages = {801--804},
	file = {Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/7VSNZZEI/Warr - 2012 - Scientific workflow systems Pipeline Pilot and KN.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/3S79SWGQ/10.html:text/html}
}

@inproceedings{wang_kepler_2009,
	address = {New York, NY, USA},
	series = {{WORKS} '09},
	title = {Kepler + {Hadoop}: {A} {General} {Architecture} {Facilitating} {Data}-intensive {Applications} in {Scientific} {Workflow} {Systems}},
	isbn = {978-1-60558-717-2},
	shorttitle = {Kepler + {Hadoop}},
	url = {http://doi.acm.org/10.1145/1645164.1645176},
	doi = {10.1145/1645164.1645176},
	abstract = {MapReduce provides a parallel and scalable programming model for data-intensive business and scientific applications. MapReduce and its de facto open source project, called Hadoop, support parallel processing on large datasets with capabilities including automatic data partitioning and distribution, load balancing, and fault tolerance management. Meanwhile, scientific workflow management systems, e.g., Kepler, Taverna, Triana, and Pegasus, have demonstrated their ability to help domain scientists solve scientific problems by synthesizing different data and computing resources. By integrating Hadoop with Kepler, we provide an easy-to-use architecture that facilitates users to compose and execute MapReduce applications in Kepler scientific workflows. Our implementation demonstrates that many characteristics of scientific workflow management systems, e.g., graphical user interface and component reuse and sharing, are very complementary to those of MapReduce. Using the presented Hadoop components in Kepler, scientists can easily utilize MapReduce in their domain-specific problems and connect them with other tasks in a workflow through the Kepler graphical user interface. We validate the feasibility of our approach via a word count use case.},
	urldate = {2016-12-20},
	booktitle = {Proceedings of the 4th {Workshop} on {Workflows} in {Support} of {Large}-{Scale} {Science}},
	publisher = {ACM},
	author = {Wang, Jianwu and Crawl, Daniel and Altintas, Ilkay},
	year = {2009},
	keywords = {Kepler, scientific workflow, parallel computing, easy-to-use, Hadoop, MapReduce, distributed computing},
	pages = {12:1--12:8},
	file = {ACM Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/U2HRFPQW/Wang et al. - 2009 - Kepler + Hadoop A General Architecture Facilitati.pdf:application/pdf}
}

@article{pizzi_aiida:_2016,
	title = {{AiiDA}: automated interactive infrastructure and database for computational science},
	volume = {111},
	issn = {0927-0256},
	shorttitle = {{AiiDA}},
	url = {http://www.sciencedirect.com/science/article/pii/S0927025615005820},
	doi = {10.1016/j.commatsci.2015.09.013},
	abstract = {Computational science has seen in the last decades a spectacular rise in the scope, breadth, and depth of its efforts. Notwithstanding this prevalence and impact, it is often still performed using the renaissance model of individual artisans gathered in a workshop, under the guidance of an established practitioner. Great benefits could follow instead from adopting concepts and tools coming from computer science to manage, preserve, and share these computational efforts. We illustrate here our paradigm sustaining such vision, based around the four pillars of Automation, Data, Environment, and Sharing. We then discuss its implementation in the open-source AiiDA platform (http://www.aiida.net), that has been tuned first to the demands of computational materials science. AiiDA’s design is based on directed acyclic graphs to track the provenance of data and calculations, and ensure preservation and searchability. Remote computational resources are managed transparently, and automation is coupled with data storage to ensure reproducibility. Last, complex sequences of calculations can be encoded into scientific workflows. We believe that AiiDA’s design and its sharing capabilities will encourage the creation of social ecosystems to disseminate codes, data, and scientific workflows.},
	urldate = {2016-12-23},
	journal = {Computational Materials Science},
	author = {Pizzi, Giovanni and Cepellotti, Andrea and Sabatini, Riccardo and Marzari, Nicola and Kozinsky, Boris},
	month = jan,
	year = {2016},
	keywords = {scientific workflow, High-throughput, Materials database, Directed acyclic graph, Provenance, Reproducibility},
	pages = {218--230},
	file = {ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/K4TGG25C/S0927025615005820.html:text/html}
}

@techreport{deelman_future_2015,
	type = {Workshop},
	title = {The {Future} of {Scientific} {Workflows}},
	url = {http://science.energy.gov/~/media/ascr/pdf/programdocuments/docs/workflows_final_report.pdf},
	abstract = {Report of the DOE NGNS/CS Scientific Workflows Workshop},
	urldate = {2016-12-26},
	institution = {U.S. Department of Energy},
	author = {Deelman, Ewa and Peterka, Tom and Altintas, Ilkay and Carothers, Christopher and Kleese van Dam, Kerstin and Moreland, Kenneth and Ramakrishnan, Lavanya and Vetter, Jeffrey},
	month = apr,
	year = {2015},
	file = {workflows_report_v3.9 - workflows_final_report.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/QI5K4PF5/workflows_final_report.pdf:application/pdf}
}

@misc{jha_towards_2016,
	title = {Towards the {Science} of {Workflows}},
	author = {Jha, Shantenu},
	year = {2016},
	file = {workflow-design-study.v0.9.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/MXJ6W955/workflow-design-study.v0.9.pdf:application/pdf}
}

@misc{montoya_apex_2016,
	title = {{APEX} {Workflows}},
	url = {https://www.nersc.gov/assets/apex-workflows-v2.pdf},
	urldate = {2016-12-23},
	author = {Montoya, David},
	year = {2016},
	file = {apex-workflows-v2.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/JFBFHNBW/apex-workflows-v2.pdf:application/pdf}
}

@techreport{clay_incorporating_2015,
	title = {Incorporating {Workflow} for {V}\&v/{Uq} in the {Sandia} {Analysis} {Workbench}.},
	url = {https://www.osti.gov/scitech/biblio/1241123},
	language = {English},
	number = {SAND2015-1556C},
	urldate = {2016-12-26},
	institution = {Sandia National Laboratories (SNL-CA), Livermore, CA (United States)},
	author = {Clay, Robert L.},
	month = mar,
	year = {2015},
	file = {Clay - 2015 - Incorporating Workflow for V&vUq in the Sandia An.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/9NVG9RZM/Clay - 2015 - Incorporating Workflow for V&vUq in the Sandia An.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/HQ5IBTAF/1241123.html:text/html}
}

@misc{the_nek5000_team_nek5000_2014,
	title = {Nek5000 {\textbar} {A} {Spectral} {Element} code for {CFD}},
	url = {https://nek5000.mcs.anl.gov/},
	urldate = {2016-12-29},
	journal = {Nek5000 Website},
	author = {{The Nek5000 Team}},
	month = oct,
	year = {2014},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/92QJI68H/nek5000.mcs.anl.gov.html:text/html}
}

@article{abraham_gromacs:_2015,
	title = {{GROMACS}: {High} performance molecular simulations through multi-level parallelism from laptops to supercomputers},
	volume = {1–2},
	issn = {2352-7110},
	shorttitle = {{GROMACS}},
	url = {http://www.sciencedirect.com/science/article/pii/S2352711015000059},
	doi = {10.1016/j.softx.2015.06.001},
	abstract = {GROMACS is one of the most widely used open-source and free software codes in chemistry, used primarily for dynamical simulations of biomolecules. It provides a rich set of calculation types, preparation and analysis tools. Several advanced techniques for free-energy calculations are supported. In version 5, it reaches new performance heights, through several new and enhanced parallelization algorithms. These work on every level; SIMD registers inside cores, multithreading, heterogeneous CPU–GPU acceleration, state-of-the-art 3D domain decomposition, and ensemble-level parallelization through built-in replica exchange and the separate Copernicus framework. The latest best-in-class compressed trajectory storage format is supported.},
	urldate = {2016-12-30},
	journal = {SoftwareX},
	author = {Abraham, Mark James and Murtola, Teemu and Schulz, Roland and Páll, Szilárd and Smith, Jeremy C. and Hess, Berk and Lindahl, Erik},
	month = sep,
	year = {2015},
	keywords = {Molecular dynamics, GPU, SIMD, Free energy},
	pages = {19--25},
	file = {ScienceDirect Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/5EFZ79E7/Abraham et al. - 2015 - GROMACS High performance molecular simulations th.pdf:application/pdf;ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/9S45MWB3/S2352711015000059.html:text/html}
}

@misc{osgi_osgi_2016,
	title = {{OSGi}™ {Alliance} – {The} {Dynamic} {Module} {System} for {Java}},
	url = {https://www.osgi.org/},
	urldate = {2016-12-31},
	author = {OSGi},
	year = {2016},
	file = {OSGi™ Alliance – The Dynamic Module System for Java:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/ZT5IG9I7/www.osgi.org.html:text/html}
}

@misc{committers_equinox_2016,
	title = {Equinox},
	url = {http://www.eclipse.org/equinox/},
	abstract = {Eclipse is probably best known as a Java IDE, but it is more: it is an IDE framework, a tools framework, an open source project, a community, an eco-system, and a foundation.},
	urldate = {2016-12-31},
	author = {Committers, Equinox},
	year = {2016},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/MZIAJJH3/equinox.html:text/html}
}

@phdthesis{fielding_architectural_2000,
	title = {Architectural {Styles} and the {Design} of {Network}-based {Software} {Architectures}},
	school = {University of California, Irvine},
	author = {Fielding, Roy Thomas},
	year = {2000},
	note = {AAI9980887}
}

@misc{wikibooks_latex/tables_2016,
	title = {{LaTeX}/{Tables} - {Wikibooks}, open books for an open world},
	url = {https://en.wikibooks.org/wiki/LaTeX/Tables},
	urldate = {2017-01-01},
	author = {Wikibooks},
	year = {2016},
	file = {LaTeX/Tables - Wikibooks, open books for an open world:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/F92RCR6F/Tables.html:text/html}
}

@misc{pontesegger_eclipse_2015,
	title = {Eclipse {Advanced} {Scripting} {Environment}},
	url = {https://eclipse.org/ease/},
	abstract = {Eclipse is probably best known as a Java IDE, but it is more: it is an IDE framework, a tools framework, an open source project, a community, an eco-system, and a foundation.},
	urldate = {2017-01-01},
	author = {Pontesegger, Christian},
	year = {2015},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/8QFSHZW9/ease.html:text/html}
}

@misc{billings_eclipse_2016,
	type = {Project {Website}},
	title = {Eclipse {ICE}},
	shorttitle = {Eclipse {ICE}},
	url = {http://www.eclipse.org/ice/},
	language = {English},
	urldate = {2017-01-01},
	journal = {Eclipse ICE},
	author = {Billings, Jay Jay},
	month = oct,
	year = {2016},
	file = {Eclipse ICE:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/3WWF697A/ice.html:text/html}
}

@inproceedings{tibbitts_integrated_2009,
	address = {Los Alamitos, CA, USA},
	title = {An integrated approach to improving the parallel application development process},
	isbn = {978-1-4244-3751-1},
	doi = {10.1109/IPDPS.2009.5160941},
	abstract = {The development of parallel applications is becoming increasingly important to a broad range of industries. Traditionally, parallel programming was a niche area that was primarily exploited by scientists trying to model extremely complicated physical phenomenon. It is becoming increasingly clear, however, that continued hardware performance improvements through clock scaling and feature-size reduction are simply not going to be achievable for much longer. The hardware vendor's approach to addressing this issue is to employ parallelism through multi-processor and multi-core technologies. While there is little doubt that this approach produces scaling improvements, there are still many significant hurdles to be overcome before parallelism can be employed as a general replacement to more traditional programming techniques. The Parallel Tools Platform (PTP) Project was created in 2005 in an attempt to provide developers with new tools aimed at addressing some of the parallel development issues. Since then, the introduction of a new generation of peta-scale and multi-core systems has highlighted the need for such a platform. In this paper, we describe some of the challenges facing parallel application developers, present the current state of PTP, and provide a simple case study that demonstrates how PTP can be used to locate a potential deadlock situation in an MPI code.},
	booktitle = {2009 {IEEE} {International} {Symposium} on {Parallel} \& {Distributed} {Processing} ({IPDPS})},
	publisher = {IEEE Computer Society},
	author = {Tibbitts, Beth R. and Watson, Gregory R. and Rasmussen, Craig E.},
	year = {2009},
	pages = {1--8},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/7VBSGBCP/05160941-abs.html:text/html}
}

@misc{billings_eclipse_2015,
	type = {Text},
	title = {Eclipse {Advanced} {Visualization} {Project}},
	url = {https://projects.eclipse.org/projects/science.eavp},
	abstract = {Visualization is a critical part of science and engineering projects and has roles in both setting up problems and post-processing results. The input or "construction" side can include things like constructing 3D geometries or volume meshes of physical space and the post-processing side can include everything from visualizing those geometries and meshes to plotting results to analyzing images to visualizing real data to almost everything else imagineable.},
	language = {und},
	urldate = {2017-01-01},
	journal = {projects.eclipse.org},
	author = {Billings, Jay Jay},
	month = dec,
	year = {2015},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/UX9AM9GR/science.html:text/html}
}

@misc{mccaskey_ornl-qci/xacc_2016,
	title = {{ORNL}-{QCI}/xacc},
	url = {https://github.com/ORNL-QCI/xacc},
	abstract = {xacc - XACC - eXtreme-scale Accelerator programming framework},
	urldate = {2017-01-01},
	journal = {GitHub},
	author = {McCaskey, Alex},
	year = {2016},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/Q4387NET/xacc.html:text/html}
}

@misc{brooks_triquetrum:_2015,
	title = {Triquetrum: {Models} of {Computation} for {Workflows}},
	shorttitle = {Triquetrum},
	url = {https://www.eclipsecon.org/na2016/session/triquetrum-models-computation-workflows},
	abstract = {Triquetrum is a new Eclipse project for managing and executing scientific workflows. The goal of Triquetrum is to support a wide range of use cases, ranging from automated processes based on predefined models, to replaying ad-hoc research workflows recorded from a user's actions in a scientific workbench UI. It will allow to define and execute models from personal pipelines with a few steps to massive models with thousands of elements.},
	urldate = {2017-01-01},
	journal = {EclipseCon NA 2016},
	author = {Brooks, Christopher},
	month = dec,
	year = {2015},
	file = {BrooksTriquetrumEclipseConNA8Mar2016.pptx - BrooksTriquetrumEclipseConNA08Mar2016.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/CH9WMBSM/BrooksTriquetrumEclipseConNA08Mar2016.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/6MZ9E6BX/triquetrum-models-computation-workflows.html:text/html}
}

@misc{graham_eclipse_2016,
	type = {Text},
	title = {Eclipse {January}},
	url = {https://projects.eclipse.org/projects/science.january},
	abstract = {Eclipse January is a set of libraries for handling numerical data in Java. It is inspired in part by NumPy and aims to provide similar functionality.},
	language = {und},
	urldate = {2017-01-01},
	journal = {projects.eclipse.org},
	author = {Graham, Jonah},
	month = apr,
	year = {2016},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/MUAQA4AJ/science.html:text/html}
}

@article{hollingsworth_workflow_1993,
	title = {Workflow management coalition the workflow reference model},
	volume = {68},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.198.5206&rep=rep1&type=pdf},
	urldate = {2017-01-03},
	journal = {Workflow Management Coalition},
	author = {Hollingsworth, David and Hampshire, U. K.},
	year = {1993},
	pages = {26},
	file = {RMV1-16.PDF - tc003v11.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/54VX8ZHD/tc003v11.pdf:application/pdf}
}

@misc{williams_6-year-old_2017,
	type = {Text.{Article}},
	title = {6-year-old accidentally orders high-end treats with {Amazon}'s {Alexa}},
	url = {http://www.foxnews.com/tech/2017/01/03/6-year-old-accidentally-orders-high-end-treats-with-amazons-alexa.html},
	abstract = {Amazon's Alexa sure is one high-class shopper.},
	language = {en-US},
	urldate = {2017-01-04},
	journal = {FoxNews.com},
	author = {Williams, Grace},
	month = jan,
	year = {2017},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/WPSSBQHR/6-year-old-accidentally-orders-high-end-treats-with-amazons-alexa.html:text/html}
}

@misc{noauthor_6-year-old_2016,
	title = {6-year-old girl used sleeping mom's fingerprints to buy {Pokemon} gifts},
	url = {http://www.dailymail.co.uk/~/article-4069090/index.html},
	abstract = {Ashlynd Howell, 6, of Maumelle, Arkansas, decided to do some shopping of her own on her mother's Amazon account, buying \$250 worth of Pokemon toys.},
	urldate = {2017-01-04},
	journal = {Mail Online},
	month = dec,
	year = {2016},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/8EPA93PQ/Mommy-shopping-Six-year-old-Arkansas-girl-used-sleeping-mom-s-fingerprints-unlock-iPhone-buy-13.html:text/html}
}

@misc{billings_[science-iwg]_2016,
	title = {[science-iwg] {Workflows}, workflows and more workflows},
	url = {https://dev.eclipse.org/mhonarc/lists/science-iwg/msg01699.html},
	urldate = {2017-01-04},
	author = {Billings, Jay Jay},
	month = apr,
	year = {2016},
	file = {[science-iwg] Workflows, workflows and more workflows:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/4WM329Q4/msg01699.html:text/html}
}

@book{weinberger_everything_2008,
	address = {New York, NY, USA},
	title = {Everything {Is} {Miscellaneous}: {The} {Power} of the {New} {Digital} {Disorder}},
	isbn = {978-0-8050-8811-3},
	shorttitle = {Everything {Is} {Miscellaneous}},
	abstract = {Human beings are information omnivores: we are constantly collecting, labeling, and organizing data. But today, the shift from the physical to the digital is mixing, burning, and ripping our lives apart. In the past, everything had its one place--the physical world demanded it--but now everything has its places: multiple categories, multiple shelves. Simply put, everything is suddenly miscellaneous. In Everything Is Miscellaneous, David Weinberger charts the new principles of digital order that are remaking business, education, politics, science, and culture. In his rollicking tour of the rise of the miscellaneous, he examines why the Dewey decimal system is stretched to the breaking point, how Rand McNally decides what information not to include in a physical map (and why Google Earth is winning that battle), how Staples stores emulate online shopping to increase sales, why your childrens teachers will stop having them memorize facts, and how the shift to digital music stands as the model for the future in virtually every industry. Finally, he shows how by "going miscellaneous," anyone can reap rewards from the deluge of information in modern work and life. From A to Z, Everything Is Miscellaneous will completely reshape the way you think--and what you know--about the world. The Flocking of Information: An Amazon.com Exclusive Essay by David Weinberger As businesses go miscellaneous, information gets chopped into smaller and smaller pieces. But it also escapes its leash--adding to a pile that can be sorted and arranged by anyone with a Web browser and a Net connection. In fact, information exhibits bird-like "flocking behavior," joining with other information that adds value to it, creating swarms that help customers and, ultimately, the businesses from which the information initially escaped. For example, Wize.com is a customer review site founded in 2005 by entrepreneur Doug Baker. The site provides reviews for everything from computers and MP3 players to coffee makers and baby strollers. But why do we need another place for reviews? If youre using the Web to research what digital camera to buy for your father-in-law, you probably feel there are far too many sites out there already. By the time you have scrolled through one stores customer reviews for each candidate camera and then cross-referenced the positive and the negative with the expert reviews at each of your bookmarked consumer magazines, you have to start the process again just to remember what people said. Wize in fact aims at exactly that problem. It pulls together reviews from many outside sources and aggregates them into three piles: user reviews, expert reviews (with links to the online publications), and the general "buzz." (For shoppers looking for a quick read on a product, Wize assigns an overall ranking.) When Wize reports that 97 percent of users love the Nikon D200 camera, it includes links to the online stores where the user reviews are posted, so customers are driven back to the businesses to spend their money. Zillow.com does something similar for real estate. The people behind Expedia.com, Rich Barton and Lloyd Frink, were looking for a new business idea--and were in the market for new homes. After hunting for information, they found that most of it was locked into the multiple listings sites of the National Association of Realtors. Now Zillow takes those listings and mashes them up with additional information that can help a potential purchaser find exactly what she wants. The most dramatic mashup right now is the "heat map" that uses swaths of color to let you tell at a glance what are the most expensive and most affordable areas. At some point, though, Zillow or one of its emerging competitors will mash up listing information with school ratings, crime maps, and aircraft flight patterns. Wize and Zillow make money by selling advertising, but their value is in the way their sites aggregate the miscellaneous--letting lots of independent sources flock together, all in one place. Were seeing the same trend in industry after industry, including music, travel, and the news media. Information gets released into the wild (sometimes against a companys will), where it joins up with other information, and the act of aggregating adds value. Companies lose some control, but they gain market presence and smarter customers. The companies that are succeeding in the new digital skies are the ones that allow their customers to add their own information and the aggregators to mix it up, because whether or not information wants to be free, it sure wants to flock.},
	publisher = {Henry Holt and Co., Inc.},
	author = {Weinberger, David},
	year = {2008}
}

@article{van_der_aalst_application_1998,
	title = {The application of petri nets to workflow management},
	volume = {08},
	issn = {0218-1266},
	url = {http://www.worldscientific.com/doi/abs/10.1142/S0218126698000043},
	doi = {10.1142/S0218126698000043},
	abstract = {Workflow management promises a new solution to an age-old problem: controlling, monitoring, optimizing and supporting business processes. What is new about workflow management is the explicit representation of the business process logic which allows for computerized support. This paper discusses the use of Petri nets in the context of workflow management. Petri nets are an established tool for modeling and analyzing processes. On the one hand, Petri nets can be used as a design language for the specification of complex workflows. On the other hand, Petri net theory provides for powerful analysis techniques which can be used to verify the correctness of workflow procedures. This paper introduces workflow management as an application domain for Petri nets, presents state-of-the-art results with respect to the verification of workflows, and highlights some Petri-net-based workflow tools.},
	number = {01},
	urldate = {2017-01-05},
	journal = {J CIRCUIT SYST COMP},
	author = {Van Der Aalst, W. M. P.},
	month = feb,
	year = {1998},
	pages = {21--66},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/GFU9QSSP/S0218126698000043.html:text/html;Van Der Aalst - 1998 - The application of petri nets to workflow manageme.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/DHDWZMXN/Van Der Aalst - 1998 - The application of petri nets to workflow manageme.pdf:application/pdf}
}

@misc{panda_panda_2016,
	title = {{PanDA} {\textless} {PanDA} {\textless} {TWiki}},
	url = {https://twiki.cern.ch/twiki/bin/view/PanDA/PanDA},
	urldate = {2017-01-05},
	author = {PanDA},
	year = {2016},
	file = {PanDA < PanDA < TWiki:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/NWDPKZCD/PanDA.html:text/html}
}

@article{megino_panda:_2015,
	series = {4th {International} {Young} {Scientist} {Conference} on {Computational} {Science}},
	title = {{PanDA}: {Evolution} and {Recent} {Trends} in {LHC} {Computing}},
	volume = {66},
	issn = {1877-0509},
	shorttitle = {{PanDA}},
	url = {http://www.sciencedirect.com/science/article/pii/S1877050915033992},
	doi = {10.1016/j.procs.2015.11.050},
	abstract = {The Large Hadron Collider(LHC) is the world's largest and most powerful machine. It started operating in 2009 with a scientific program foreseen to extend over the next coming decades at increasing energies and luminosities to maximise the discovery potential. During Run1 (2009- 2013), the Worldwide LHC Computing Grid (WLCG) successfully delivered all the necessary computing resources, which made the discovery of the Higgs Boson possible. Looking ahead, it is forecasted that increased luminosities will extrapolate to a multiplicity in the storage and processing costs, which is not reflected in a corresponding funding growth of the WLCG. ATLAS, one of the four experiments at the LHC, is therefore leading an upgrade program to evolve their software and computing model to make the best possible usage of available resources, and also leverage on upcoming state of the art computing paradigms that could make important resource contributions. These proceedings will give an insight into the accompanying work in PanDA, ATLAS’ workload management system. PanDA has implemented event level bookkeeping and dynamic generation of jobs with tailored lengths, in order to integrate and optimise the usage of oppor- tunistic resources, e.g. Cloud Computing or High Performance Computing (HPC). In conjunc- tion, the Event Service has been developed as a way to manage fine grained jobs and its outputs. Usage examples on some of the leading commercial and research infrastructures will be given. In addition, we will describe the work on further exploiting the current network capabilities by allowing remote data access and reducing regional boundaries.},
	urldate = {2017-01-05},
	journal = {Procedia Computer Science},
	author = {Megino, Fernando Barreiro and De, Kaushik and Caballero, Jose and Hover, John and Klimentov, Alexei and Maeno, Tadashi and Nilsson, Paul and Oleynik, Danila and Padolski, Sergey and Panitkin, Sergey and Petrosyan, Artem and Wenaus, Torre},
	month = jan,
	year = {2015},
	keywords = {Grid computing, Cloud computing, Workload Management System, ATLAS, HPC},
	pages = {439--447},
	file = {PanDA\: Evolution and Recent Trends in LHC Computing - 1-s2.0-S1877050915033992-main.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/6XCIZXSQ/1-s2.0-S1877050915033992-main.pdf:application/pdf;ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/QQMH9XE8/S1877050915033992.html:text/html}
}

@techreport{barker_high_2016,
	title = {High {Performance} {Computing} {Facility} {Operational} {Assessment} 2015: {Oak} {Ridge} {Leadership} {Computing} {Facility}},
	shorttitle = {High {Performance} {Computing} {Facility} {Operational} {Assessment} 2015},
	url = {https://www.osti.gov/scitech/biblio/1324094},
	language = {English},
	number = {ORNL/SPR--2016/110},
	urldate = {2017-01-05},
	institution = {Oak Ridge National Lab. (ORNL), Oak Ridge, TN (United States). Oak Ridge Leadership Computing Facility (OLCF)},
	author = {Barker, Ashley D. and Bernholdt, David E. and Bland, Arthur S. and Gary, Jeff D. and Hack, James J. and McNally, Stephen T. and Rogers, James H. and Smith, Brian E. and Straatsma, T. P. and Sukumar, Sreenivas Rangan and Thach, Kevin G. and Tichenor, Suzy and Vazhkudai, Sudharshan S. and Wells, Jack C.},
	month = mar,
	year = {2016},
	keywords = {mathematics and computing},
	file = {Barker et al. - 2016 - High Performance Computing Facility Operational As.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/R6A32ENF/Barker et al. - 2016 - High Performance Computing Facility Operational As.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/KE2568A9/1324094.html:text/html}
}

@misc{nersc_apex_2016,
	title = {{APEX}},
	url = {http://www.nersc.gov/research-and-development/apex/},
	urldate = {2017-01-05},
	author = {NERSC},
	year = {2016},
	file = {APEX:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/UUJKPTVP/apex.html:text/html}
}

@misc{pack_sos20_2016,
	title = {{SOS}20},
	url = {http://www.csm.ornl.gov/SOS20/agenda.html},
	urldate = {2017-01-05},
	author = {Pack, Daniel},
	month = mar,
	year = {2016},
	file = {SOS20:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/3ZRQPFJA/agenda.html:text/html}
}

@article{xsede_xsede_2013,
	title = {{XSEDE} {Cloud} {Survey} {Report}},
	url = {https://www.ideals.illinois.edu/handle/2142/45766},
	abstract = {A NSF-sponsored cloud user survey was conducted by XSEDE to better understand how cloud is used across a wide variety of scientific fields and the humanities, arts, and social sciences. Data was collected from 80 cloud users from around the globe. The project descriptions in this report illustrate the potential of cloud in accelerating research, enhancing collaboration, and enriching education. Cloud users provided extensive data on core usage, preferred storage, bandwidth, etc. and described cloud benefits and limitations for their specific use cases.},
	language = {en},
	urldate = {2017-01-05},
	author = {XSEDE},
	month = sep,
	year = {2013},
	file = {Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/4RRDA5KQ/2013 - XSEDE Cloud Survey Report.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/SU3NUHAJ/45766.html:text/html}
}

@misc{mai_cesm_nodate,
	title = {{CESM} {Workflow} - {CSEG} - {CESM} {Model} {Work} {Flow} - wiki.ucar.edu},
	url = {https://wiki.ucar.edu/display/CESMworkFlow/CESM+Workflow},
	urldate = {2017-01-10},
	author = {Mai, Andrew},
	file = {CESM Workflow - CSEG - CESM Model Work Flow - wiki.ucar.edu:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/7I834PDH/CESM+Workflow.html:text/html}
}

@misc{noauthor_imixs-workflow_nodate,
	title = {Imixs-{Workflow} - {Open} {Source} {Workflow} {Engine} {BPMN}},
	url = {http://www.imixs.org/},
	urldate = {2017-01-10},
	file = {Imixs-Workflow - Open Source Workflow Engine BPMN:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/CXCHX2G3/www.imixs.org.html:text/html}
}

@misc{noauthor_screenshot_nodate,
	title = {screenshot - {Shutter} snapshot tool to copy image to clipboard - {Ask} {Ubuntu}},
	url = {http://askubuntu.com/questions/799588/shutter-snapshot-tool-to-copy-image-to-clipboard},
	urldate = {2017-01-11},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/FSNBKUEW/shutter-snapshot-tool-to-copy-image-to-clipboard.html:text/html}
}

@inproceedings{li_sla-driven_2010,
	address = {New York, NY, USA},
	series = {{WOSP}/{SIPEW} '10},
	title = {{SLA}-driven {Planning} and {Optimization} of {Enterprise} {Applications}},
	isbn = {978-1-60558-563-5},
	url = {http://doi.acm.org/10.1145/1712605.1712625},
	doi = {10.1145/1712605.1712625},
	abstract = {We propose a model-based methodology to size and plan enterprise applications subject to Service Level Agreements (SLAs). Our approach is illustrated using a real-world Enterprise Resource Planning (ERP) application, namely SAP ERP. Firstly, we develop a closed queueing network model with finite capacity regions describing the SAP ERP application performance and show that this model is effective and robust in capturing measured response times and utilizations. Secondly, we propose an analytical cost model that jointly accounts for fixed hardware costs and dynamic operational costs related to power consumption. Based on the developed performance and cost models, we propose to use multi-objective optimization to find the Pareto-optimal solutions that describe the best trade-off solutions between conflicting performance and cost-saving goals. Experimental validation demonstrates the accuracy of the proposed models and shows that the attained Pareto-optimal solutions can be efficiently used by service providers for SLA-driven planning decisions, thus making a strong case in favor of the applicability of our methodology for deployment decisions subject to different SLA requirements.},
	urldate = {2017-01-20},
	booktitle = {Proceedings of the {First} {Joint} {WOSP}/{SIPEW} {International} {Conference} on {Performance} {Engineering}},
	publisher = {ACM},
	author = {Li, Hui and Casale, Giuliano and Ellahi, Tariq},
	year = {2010},
	keywords = {cost modeling, multi-objective optimization, performance modeling, service level agreements},
	pages = {117--128},
	file = {Li et al. - 2010 - SLA-driven Planning and Optimization of Enterprise.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/7BC6TRM9/Li et al. - 2010 - SLA-driven Planning and Optimization of Enterprise.pdf:application/pdf}
}

@article{ferreira_da_silva_characterization_2017,
	title = {A characterization of workflow management systems for extreme-scale applications},
	volume = {75},
	issn = {0167-739X},
	url = {http://www.sciencedirect.com/science/article/pii/S0167739X17302510},
	doi = {10.1016/j.future.2017.02.026},
	abstract = {Automation of the execution of computational tasks is at the heart of improving scientific productivity. Over the last years, scientific workflows have been established as an important abstraction that captures data processing and computation of large and complex scientific applications. By allowing scientists to model and express entire data processing steps and their dependencies, workflow management systems relieve scientists from the details of an application and manage its execution on a computational infrastructure. As the resource requirements of today’s computational and data science applications that process vast amounts of data keep increasing, there is a compelling case for a new generation of advances in high-performance computing, commonly termed as extreme-scale computing, which will bring forth multiple challenges for the design of workflow applications and management systems. This paper presents a novel characterization of workflow management systems using features commonly associated with extreme-scale computing applications. We classify 15 popular workflow management systems in terms of workflow execution models, heterogeneous computing environments, and data access methods. The paper also surveys workflow applications and identifies gaps for future research on the road to extreme-scale workflows and management systems.},
	number = {2017},
	urldate = {2017-02-21},
	journal = {Future Generation Computer Systems},
	author = {Ferreira da Silva, Rafael and Filgueira, Rosa and Pietri, Ilia and Jiang, Ming and Sakellariou, Rizos and Deelman, Ewa},
	month = oct,
	year = {2017},
	keywords = {Workflow Management Systems, scientific workflows, Extreme-scale computing, in situ processing},
	pages = {228--238},
	file = {ScienceDirect Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/TE4UC2KD/Ferreira da Silva et al. - A characterization of workflow management systems .pdf:application/pdf;ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/K774SQ5T/S0167739X17302510.html:text/html}
}

@article{deelman_future_2017,
	title = {The future of scientific workflows},
	issn = {1094-3420},
	url = {http://dx.doi.org/10.1177/1094342017704893},
	doi = {10.1177/1094342017704893},
	abstract = {Today’s computational, experimental, and observational sciences rely on computations that involve many related tasks. The success of a scientific mission often hinges on the computer automation of these workflows. In April 2015, the US Department of Energy (DOE) invited a diverse group of domain and computer scientists from national laboratories supported by the Office of Science, the National Nuclear Security Administration, from industry, and from academia to review the workflow requirements of DOE’s science and national security missions, to assess the current state of the art in science workflows, to understand the impact of emerging extreme-scale computing systems on those workflows, and to develop requirements for automated workflow management in future and existing environments. This article is a summary of the opinions of over 50 leading researchers attending this workshop. We highlight use cases, computing systems, workflow needs and conclude by summarizing the remaining challenges this community sees that inhibit large-scale scientific workflows from becoming a mainstream tool for extreme-scale science.},
	language = {en},
	urldate = {2017-05-10},
	journal = {Int'l Jnl of High Perf Comp Applictns},
	author = {Deelman, Ewa and Peterka, Tom and Altintas, Ilkay and Carothers, Christopher D and Kleese van Dam, Kerstin and Moreland, Kenneth and Parashar, Manish and Ramakrishnan, Lavanya and Taufer, Michela and Vetter, Jeffrey},
	month = apr,
	year = {2017},
	pages = {1094342017704893},
	file = {SAGE PDF Full Text:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/U8BJFSRM/Deelman et al. - 2017 - The future of scientific workflows.pdf:application/pdf}
}

@article{billings_eclipse_2017,
	title = {The {Eclipse} {Integrated} {Computational} {Environment}},
	url = {http://arxiv.org/abs/1704.01398},
	abstract = {Problems in modeling and simulation require significantly different workflow management technologies than standard grid-based workflow management systems. Computational scientists typically interact with simulation software in a feedback driven way were solutions and workflows are developed iteratively and simultaneously. This work describes common activities in workflows and how combinations of these activities form unique workflows. It presents the Eclipse Integrated Computational Environment as a workflow management system and development environment for the modeling and simulation community. Examples of the Environment's applicability to problems in energy science, general multiphysics simulations, quantum computing and other areas are presented as well as its impact on the community.},
	urldate = {2017-05-23},
	journal = {arXiv:1704.01398 [cs]},
	author = {Billings, Jay Jay and Bennett, Andrew R. and Deyton, Jordan and Gammeltoft, Kasper and Graham, Jonah and Gorin, Dasha and Krishnan, Hari and Li, Menghan and McCaskey, Alexander J. and Patterson, Taylor and Smith, Robert and Watson, Gregory R. and Wojtowicz, Anna},
	month = mar,
	year = {2017},
	note = {arXiv: 1704.01398},
	keywords = {Computer Science - Software Engineering, Computer Science - Computational Engineering, Finance, and Science},
	file = {arXiv\:1704.01398 PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/TFFIW7U2/Billings et al. - 2017 - The Eclipse Integrated Computational Environment.pdf:application/pdf;arXiv.org Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/ZAXFHQRG/1704.html:text/html}
}

@misc{noauthor_bibtex_nodate,
	title = {bibtex - {How} to write “ä” and other umlauts and accented letters in bibliography? - {TeX} - {LaTeX} {Stack} {Exchange}},
	shorttitle = {bibtex - {How} to write “ä” and other umlauts and accented letters in bibliography?},
	url = {https://tex.stackexchange.com/questions/57743/how-to-write-%C3%A4-and-other-umlauts-and-accented-letters-in-bibliography},
	urldate = {2017-10-18},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/P3RDRKHJ/how-to-write-ä-and-other-umlauts-and-accented-letters-in-bibliography.html:text/html}
}

@inproceedings{billings_toward_2017,
	address = {Denver, Colorado},
	title = {Toward {Common} {Components} for {Open} {Workflow} {Systems}},
	url = {http://arxiv.org/abs/1710.06774},
	abstract = {The role of scalable high-performance workflows and flexible workflow management systems that can support multiple simulations will continue to increase in importance. For example, with the end of Dennard scaling, there is a need to substitute a single long running simulation with multiple repeats of shorter simulations, or concurrent replicas. Further, many scientific problems involve ensembles of simulations in order to solve a higher-level problem or produce statistically meaningful results. However most supercomputing software development and performance enhancements have focused on optimizing single- simulation performance. On the other hand, there is a strong inconsistency in the definition and practice of workflows and workflow management systems. This inconsistency often centers around the difference between several different types of workflows, including modeling and simulation, grid, uncertainty quantification, and purely conceptual workflows. This work explores this phenomenon by examining the different types of workflows and workflow management systems, reviewing the perspective of a large supercomputing facility, examining the common features and problems of workflow management systems, and finally presenting a proposed solution based on the concept of common building blocks. The implications of the continuing proliferation of workflow management systems and the lack of interoperability between these systems are discussed from a practical perspective. In doing so, we have begun an investigation of the design and implementation of open workflow systems for supercomputers based upon common components.},
	urldate = {2017-12-20},
	booktitle = {{arXiv}:1710.06774 [cs]},
	author = {Billings, Jay Jay and Jha, Shantenu},
	month = nov,
	year = {2017},
	note = {arXiv: 1710.06774},
	keywords = {Computer Science - Software Engineering},
	file = {arXiv\:1710.06774 PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/5TU72E9N/Billings and Jha - 2017 - Toward Common Components for Open Workflow Systems.pdf:application/pdf;arXiv.org Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/Q8LAZK69/1710.html:text/html}
}

@misc{noauthor_sc17_nodate,
	title = {{SC}17 {OpenSuCo} 2017 – {OpenSuCo}},
	url = {http://www.opensuco.community/2017/04/28/sc17-opensuco-2017/},
	urldate = {2017-12-20},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/XLSWF2RQ/sc17-opensuco-2017.html:text/html}
}

@misc{noauthor_common-workflow-language:_2018,
	title = {common-workflow-language: {Repository} for {CWL} {Specifications}. {Use} https://www.biostars.org/t/cwl/ for support},
	shorttitle = {common-workflow-language},
	url = {https://github.com/common-workflow-language/common-workflow-language},
	urldate = {2018-01-22},
	publisher = {Common Workflow Language},
	month = jan,
	year = {2018},
	note = {original-date: 2014-09-25T11:04:47Z},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/N9GEFSI3/Existing-Workflow-systems.html:text/html}
}

@misc{noauthor_proposal:_nodate,
	title = {proposal: {HardwareRequirement} · {Issue} \#587 · common-workflow-language/common-workflow-language},
	shorttitle = {proposal},
	url = {https://github.com/common-workflow-language/common-workflow-language/issues/587},
	abstract = {HardwareRequirement
Specify that a tool requires special hardware feature that cannot be provided through software alone.
Example:
requirements:
  HardwareRequirement:
    hardware:
      - hwtype:...},
	language = {en},
	urldate = {2018-01-22},
	journal = {GitHub},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/BL3TTP8J/587.html:text/html}
}

@misc{noauthor_ibisba_nodate,
	title = {{IBISBA} 1.0},
	url = {http://www.esciencelab.org.uk/projects/ibisba/},
	urldate = {2018-01-22},
	file = {IBISBA 1.0:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/QSEBNMWM/ibisba.html:text/html}
}

@misc{noauthor_reana_nodate,
	title = {{REANA} - {Reusable} {Analyses} — reana 0.0.1.dev20170123 documentation},
	url = {https://reana.readthedocs.io/en/latest/},
	urldate = {2018-01-22},
	file = {REANA - Reusable Analyses — reana 0.0.1.dev20170123 documentation:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/LLYGI5YC/latest.html:text/html}
}

@misc{noauthor_wf4ever_nodate,
	title = {Wf4Ever {Research} {Object} {Model}},
	url = {http://wf4ever.github.io/ro/#wfdesc},
	urldate = {2018-01-22},
	file = {Wf4Ever Research Object Model:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/MU4M64ER/ro.html:text/html}
}

@misc{daviddarnes_p-recs_nodate,
	title = {P-{RECS}},
	url = {https://p-recs.github.io/2018/},
	abstract = {This workshop is going to be fun.},
	language = {en-GB},
	urldate = {2018-01-22},
	journal = {P-RECS},
	author = {DavidDarnes},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/BT7DLCP8/2018.html:text/html}
}

@misc{noauthor_common-workflow-language/common-workflow-language_nodate,
	title = {common-workflow-language/common-workflow-language},
	url = {https://gitter.im/common-workflow-language/common-workflow-language},
	abstract = {Where developers come to talk.},
	language = {en},
	urldate = {2018-01-22},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/IM7PEV67/common-workflow-language.html:text/html}
}

@misc{noauthor_3_nodate,
	title = {(3) {Blockchains} for {Business} {Process} {Management} - {Challenges} and {Opportunities}},
	url = {https://www.researchgate.net/publication/316076240_Blockchains_for_Business_Process_Management_-_Challenges_and_Opportunities},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2018-03-27},
	journal = {ResearchGate},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/KTFPQMT6/316076240_Blockchains_for_Business_Process_Management_-_Challenges_and_Opportunities.html:text/html}
}

@misc{noauthor_blockchains_nodate,
	title = {Blockchains for {Business} {Process} {Management} - {Challenges} and {Opportunities}},
	url = {https://www.researchgate.net/publication/316076240_Blockchains_for_Business_Process_Management_-_Challenges_and_Opportunities},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2018-03-27},
	journal = {ResearchGate},
	file = {Blockchains for Business Process Management - Chal.PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/JT7B6E68/Blockchains for Business Process Management - Chal.PDF:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/KPA9LIGV/316076240_Blockchains_for_Business_Process_Management_-_Challenges_and_Opportunities.html:text/html}
}

@article{worley_scrybe:_nodate,
	title = {Scrybe: {A} 2nd-{Generation} {Blockchain} {Technology} with {Lightweight} {Mining} for {Secure} {Provenance} and {Related} {Applications}},
	abstract = {The recent popularity of cryptocurrencies has highlighted the versatility and applications of a decentralized, public blockchain. Blockchains provide a data structure that can guarantee both the integrity and non-repudiation of data, as well as providing provenance pertaining to such data. Our novel Lightweight Mining (LWM) algorithm provides these guarantees with minimal resource requirements. Our approach to blockchain-based data provenance, paired with the LWM algorithm, provides the legal and ethical framework for key classes of provenance to be managed.},
	language = {en},
	author = {Worley, Carl and Yu, Lu and Brooks, Richard R and Hambolu, Owulakemi and Oakley, Jon and Skjellum, Anthony and Altarawneh, Amani and Obeid, Jihad S and Lenert, Leslie and Wang, K C and Mukhopadhyay, Ujan},
	pages = {8},
	file = {Worley et al. - Scrybe A 2nd-Generation Blockchain Technology wit.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/7XL6WEN4/Worley et al. - Scrybe A 2nd-Generation Blockchain Technology wit.pdf:application/pdf}
}

@inproceedings{woodman_workflow_2015,
	address = {New York, NY, USA},
	series = {{WORKS} '15},
	title = {Workflow {Provenance}: {An} {Analysis} of {Long} {Term} {Storage} {Costs}},
	isbn = {978-1-4503-3989-6},
	shorttitle = {Workflow {Provenance}},
	url = {http://doi.acm.org/10.1145/2822332.2822341},
	doi = {10.1145/2822332.2822341},
	abstract = {The storage and retrieval of provenance is a critical piece of functionality for many data processing systems. There are numerous cases where, in order to satisfy regulatory requirements (such as drug development and medical data processing), accurately reproduce results (scientific research) or to maintain financial transparency (for example to meet Sarbanes Oxley regulations in the US), a full and accurate provenance trace is vital. Whilst it is always possible to meet these requirements by storing every piece of intermediate data generated by a sequence of calculations, the costs associated with retaining data that may have a low probability of future retrieval is significant. There is, however, an opportunity for a reduction in the cost of storage by opting not to store certain intermediate results that can be regenerated given a knowledge of the processing code and input data that generated them. This paper presents a approach which is able, via a collection of past performance and provenance data, to make decisions based on the underlying storage and computation costs as to which intermediate data to retain and which to regenerate on demand.},
	urldate = {2018-04-07},
	booktitle = {Proceedings of the 10th {Workshop} on {Workflows} in {Support} of {Large}-{Scale} {Science}},
	publisher = {ACM},
	author = {Woodman, Simon and Hiden, Hugo and Watson, Paul},
	year = {2015},
	pages = {9:1--9:9},
	file = {ACM Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/WTSJVMI9/Woodman et al. - 2015 - Workflow Provenance An Analysis of Long Term Stor.pdf:application/pdf}
}

@misc{noauthor_prov-overview_nodate,
	title = {{PROV}-{Overview}},
	url = {https://www.w3.org/TR/prov-overview/},
	urldate = {2018-04-08},
	keywords = {Provenance},
	file = {PROV-Overview:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/9GD5AAXG/prov-overview.html:text/html}
}

@misc{noauthor_provenance_nodate,
	title = {Provenance {Web} {Services}},
	url = {https://openprovenance.org/},
	urldate = {2018-04-08},
	file = {Provenance Web Services:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/FBSMPBYD/openprovenance.org.html:text/html}
}

@article{yue_sharing_2011,
	title = {Sharing geospatial provenance in a service-oriented environment},
	volume = {35},
	issn = {0198-9715},
	url = {http://www.sciencedirect.com/science/article/pii/S0198971511000275},
	doi = {10.1016/j.compenvurbsys.2011.02.006},
	abstract = {One of the earliest investigations of provenance was inspired by applications in GIS in the early 1990’s. Provenance records the processing history of a data product. It provides an information context to help users determine the reliability of data products. Conventional provenance applications in GIS focus on provenance capture, representation, and usage in a stand-alone environment such as a desktop-based GIS software system. They cannot support wide sharing and open access of provenance in a distributed environment. The growth of service-oriented sharing and processing of geospatial data brings some new challenges in provenance-aware applications. One is how to share geospatial provenance in an interoperable way. This paper describes the development of provenance service for geospatial data products using the ebXML Registry Information Model (ebRIM) of a geospatial catalog service, which follows the interface specifications of the OGC Catalogue Services for the Web (CSW). This approach fits well the current service stack of the GIS domain and facilitates the management of geospatial data provenance in an open and distributed environment.},
	number = {4},
	urldate = {2018-04-08},
	journal = {Computers, Environment and Urban Systems},
	author = {Yue, Peng and Wei, Yaxing and Di, Liping and He, Lianlian and Gong, Jianya and Zhang, Liangpei},
	month = jul,
	year = {2011},
	keywords = {CSW, Data provenance, ebRIM, Geospatial Web Service, GIS, Service chaining},
	pages = {333--343},
	file = {ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/LX7WJCJE/S0198971511000275.html:text/html}
}

@article{karvounarakis_provenance_2009,
	title = {Provenance in collaborative data sharing},
	url = {https://repository.upenn.edu/dissertations/AAI3381632},
	journal = {Dissertations available from ProQuest},
	author = {Karvounarakis, Grigorios},
	month = jan,
	year = {2009},
	pages = {1--195},
	file = {"Provenance in collaborative data sharing" by Grigorios Karvounarakis:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/WBQKT2IE/AAI3381632.html:text/html}
}

@article{moreau_open_2011,
	title = {The {Open} {Provenance} {Model} core specification (v1.1)},
	volume = {27},
	issn = {0167739X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167739X10001275},
	doi = {10.1016/j.future.2010.07.005},
	language = {en},
	number = {6},
	urldate = {2018-04-08},
	journal = {Future Generation Computer Systems},
	author = {Moreau, Luc and Clifford, Ben and Freire, Juliana and Futrelle, Joe and Gil, Yolanda and Groth, Paul and Kwasnikowska, Natalia and Miles, Simon and Missier, Paolo and Myers, Jim and Plale, Beth and Simmhan, Yogesh and Stephan, Eric and den Bussche, Jan Van},
	month = jun,
	year = {2011},
	pages = {743--756}
}

@article{ragan_characterizing_2016,
	title = {Characterizing {Provenance} in {Visualization} and {Data} {Analysis}: {An} {Organizational} {Framework} of {Provenance} {Types} and {Purposes}},
	volume = {22},
	issn = {1077-2626},
	shorttitle = {Characterizing {Provenance} in {Visualization} and {Data} {Analysis}},
	url = {http://ieeexplore.ieee.org/document/7192714/},
	doi = {10.1109/TVCG.2015.2467551},
	abstract = {While the primary goal of visual analytics research is to improve the quality of insights and ﬁndings, a substantial amount of research in provenance has focused on the history of changes and advances throughout the analysis process. The term, provenance, has been used in a variety of ways to describe different types of records and histories related to visualization. The existing body of provenance research has grown to a point where the consolidation of design knowledge requires cross-referencing a variety of projects and studies spanning multiple domain areas. We present an organizational framework of the different types of provenance information and purposes for why they are desired in the ﬁeld of visual analytics. Our organization is intended to serve as a framework to help researchers specify types of provenance and coordinate design knowledge across projects. We also discuss the relationships between these factors and the methods used to capture provenance information. In addition, our organization can be used to guide the selection of evaluation methodology and the comparison of study outcomes in provenance research.},
	language = {en},
	number = {1},
	urldate = {2018-04-08},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ragan, Eric D. and Endert, Alex and Sanyal, Jibonananda and Chen, Jian},
	month = jan,
	year = {2016},
	keywords = {Provenance, Analytic provenance, Cognition, Conceptual model, coordinate design knowledge, data analysis, Data analysis, data visualisation, Data visualization, Framework, History, organizational framework, Organizations, provenance characterization, visual analytics, Visual analytics, visualization, Visualization},
	pages = {31--40},
	file = {IEEE Xplore Abstract Record:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/I8QJS4HN/7192714.html:text/html;Ragan et al. - 2016 - Characterizing Provenance in Visualization and Dat.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/CEICU24T/Ragan et al. - 2016 - Characterizing Provenance in Visualization and Dat.pdf:application/pdf}
}

@article{nakamoto_bitcoin:_nodate,
	title = {Bitcoin: {A} {Peer}-to-{Peer} {Electronic} {Cash} {System}},
	abstract = {A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.},
	language = {en},
	author = {Nakamoto, Satoshi},
	pages = {9},
	file = {Nakamoto - Bitcoin A Peer-to-Peer Electronic Cash System.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/92Q32WMB/Nakamoto - Bitcoin A Peer-to-Peer Electronic Cash System.pdf:application/pdf}
}

@misc{noauthor_proof--stake_2018,
	title = {Proof-of-stake},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Proof-of-stake&oldid=833753016},
	abstract = {Proof of stake (PoS) is a type of algorithm by which a cryptocurrency blockchain network aims to achieve distributed consensus. In PoS-based cryptocurrencies, the creator of the next block is chosen via various combinations of random selection and wealth or age (i.e., the stake). In contrast, the algorithm of proof-of-work-based cryptocurrencies such as bitcoin uses mining; that is, the solving of computationally intensive puzzles to validate transactions and create new blocks.},
	language = {en},
	urldate = {2018-04-09},
	journal = {Wikipedia},
	month = apr,
	year = {2018},
	note = {Page Version ID: 833753016},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/QXAMUHYY/index.html:text/html}
}

@misc{noauthor_groups:requirements:use-case-inventory_nodate,
	title = {groups:requirements:use-case-inventory [{Hyperledger} {Wiki}]},
	url = {https://wiki.hyperledger.org/groups/requirements/use-case-inventory},
	urldate = {2018-04-09},
	file = {groups\:requirements\:use-case-inventory [Hyperledger Wiki]:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/8DYNHUJM/use-case-inventory.html:text/html}
}

@misc{noauthor_discussion_2018,
	title = {Discussion of blockchains for the {Blockchain} {Community} {Group} and workshops},
	url = {https://github.com/w3c/blockchain},
	urldate = {2018-04-09},
	publisher = {World Wide Web Consortium},
	month = mar,
	year = {2018},
	note = {original-date: 2016-05-05T13:56:08Z},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/AZQDWI4N/Use-Cases.html:text/html}
}

@techreport{sompolinsky_phantom:_2018,
	title = {{PHANTOM}: {A} {Scalable} {BlockDAG} {Protocol}},
	shorttitle = {{PHANTOM}},
	url = {http://eprint.iacr.org/2018/104},
	abstract = {In 2008 Satoshi Nakamoto invented the basis for what would come to be known as blockchain technology. The core concept of this system is an open and anonymous network of nodes, or miners, which together maintain a public ledger of transactions. The ledger takes the form of a chain of blocks, the blockchain, where each block is a batch of new transactions collected from users.



One primary problem with Satoshi's blockchain is its highly limited scalability. The security of Satoshi's longest chain rule, more generally known as the Bitcoin protocol, requires that all honest nodes be aware of each other's blocks in real time. To this end, the throughput is artificially suppressed so that each block fully propagates before the next one is created, and that no ``orphan blocks'' that fork the chain be created spontaneously. In this paper we present PHANTOM, a protocol for transaction confirmation that is secure under any throughput that the network can support. PHANTOM thus does not suffer from the security-scalability tradeoff which Satoshi's protocol suffers from. PHANTOM utilizes a Directed Acyclic Graph of blocks, aka blockDAG, a generalization of Satoshi's chain which better suits a setup of fast or large blocks. PHANTOM uses a greedy algorithm on the blockDAG to distinguish between blocks mined properly by honest nodes and those mined by non-cooperating nodes that deviated from the DAG mining protocol. Using this distinction, PHANTOM provides a full order on the blockDAG in a way that is eventually agreed upon by all honest nodes.},
	number = {104},
	urldate = {2018-04-09},
	author = {Sompolinsky, Yonatan and Zohar, Aviv},
	year = {2018},
	keywords = {applications, BlockDAG, Consensus Protocols, Cryptocurrency},
	file = {ePrint IACR Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/PCLHC9ZR/Sompolinsky and Zohar - 2018 - PHANTOM A Scalable BlockDAG Protocol.pdf:application/pdf;ePrint IACR Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/TM5EXAYE/104.html:text/html}
}

@article{cachin_architecture_nodate,
	title = {Architecture of the {Hyperledger} {Blockchain} {Fabric}∗},
	language = {en},
	author = {Cachin, Christian},
	pages = {4},
	file = {Cachin - Architecture of the Hyperledger Blockchain Fabric∗.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/UCZ6RLJX/Cachin - Architecture of the Hyperledger Blockchain Fabric∗.pdf:application/pdf}
}

@inproceedings{merkle_digital_1987,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Digital} {Signature} {Based} on a {Conventional} {Encryption} {Function}},
	isbn = {978-3-540-18796-7 978-3-540-48184-3},
	url = {https://link.springer.com/chapter/10.1007/3-540-48184-2_32},
	doi = {10.1007/3-540-48184-2_32},
	abstract = {A new digital signature based only on a conventional encryption function (such as DES) is described which is as secure as the underlying encryption function -- the security does not depend on the difficulty of factoring and the high computational costs of modular arithmetic are avoided. The signature system can sign an unlimited number of messages, and the signature size increases logarithmically as a function of the number of messages signed. Signature size in a ‘typical’ system might range from a few hundred bytes to a few kilobytes, and generation of a signature might require a few hundred to a few thousand computations of the underlying conventional encryption function.},
	language = {en},
	urldate = {2018-04-09},
	booktitle = {Advances in {Cryptology} — {CRYPTO} ’87},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Merkle, Ralph C.},
	month = aug,
	year = {1987},
	pages = {369--378},
	file = {Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/VMSVPXE7/Merkle - 1987 - A Digital Signature Based on a Conventional Encryp.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/CNJY2HW7/10.html:text/html}
}

@book{richard_brooks_and_anthony_skjellum_using_2017,
	title = {Using the {Blockchain} to {Secure} {Provenance} {Meta}-{Data} ({A} {CCoE} {Webinar} {Presentation})},
	author = {{Richard Brooks and Anthony Skjellum}},
	month = jun,
	year = {2017},
	annote = {Technical presentation. NCCoE seminar}
}

@misc{noauthor_hyperledger_nodate,
	title = {Hyperledger {Fabric}},
	url = {https://www.hyperledger.org/projects/fabric},
	language = {en-US},
	urldate = {2018-04-10},
	journal = {Hyperledger},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/GYZ6BBQS/fabric.html:text/html}
}

@article{mendling_blockchains_2018,
	title = {Blockchains for {Business} {Process} {Management} - {Challenges} and {Opportunities}},
	volume = {9},
	issn = {2158-656X},
	url = {http://doi.acm.org/10.1145/3183367},
	doi = {10.1145/3183367},
	abstract = {Blockchain technology offers a sizable promise to rethink the way interorganizational business processes are managed because of its potential to realize execution without a central party serving as a single point of trust (and failure). To stimulate research on this promise and the limits thereof, in this article, we outline the challenges and opportunities of blockchain for business process management (BPM). We first reflect how blockchains could be used in the context of the established BPM lifecycle and second how they might become relevant beyond. We conclude our discourse with a summary of seven research directions for investigating the application of blockchain technology in the context of BPM.},
	number = {1},
	urldate = {2018-04-10},
	journal = {ACM Trans. Manage. Inf. Syst.},
	author = {Mendling, Jan and Weber, Ingo and Aalst, Wil Van Der and Brocke, Jan Vom and Cabanillas, Cristina and Daniel, Florian and Debois, Søren and Ciccio, Claudio Di and Dumas, Marlon and Dustdar, Schahram and Gal, Avigdor and García-Bañuelos, Luciano and Governatori, Guido and Hull, Richard and Rosa, Marcello La and Leopold, Henrik and Leymann, Frank and Recker, Jan and Reichert, Manfred and Reijers, Hajo A. and Rinderle-Ma, Stefanie and Solti, Andreas and Rosemann, Michael and Schulte, Stefan and Singh, Munindar P. and Slaats, Tijs and Staples, Mark and Weber, Barbara and Weidlich, Matthias and Weske, Mathias and Xu, Xiwei and Zhu, Liming},
	month = feb,
	year = {2018},
	keywords = {Blockchain, business process management, research challenges},
	pages = {4:1--4:16}
}

@article{tovar_job_2018,
	title = {A {Job} {Sizing} {Strategy} for {High}-{Throughput} {Scientific} {Workflows}},
	volume = {29},
	issn = {1045-9219},
	doi = {10.1109/TPDS.2017.2762310},
	abstract = {The user of a computing facility must make a critical decision when submitting jobs for execution: how many resources (such as cores, memory, and disk) should be requested for each job? If the request is too small, the job may fail due to resource exhaustion; if the request is too large, the job may succeed, but resources will be wasted. This decision is especially important when running hundreds of thousands of jobs in a high throughput workflow, which may exhibit complex, long tailed distributions of resource consumption. In this paper, we present a strategy for solving the job sizing problem: (1) applications are monitored and measured in user-space as they run; (2) the resource usage is collected into an online archive; and (3) jobs are automatically sized according to historical data in order to maximize throughput or minimize waste. We evaluate the solution analytically, and present case studies of applying the technique to high throughput physics and bioinformatics workflows consisting of hundreds of thousands of jobs, demonstrating an increase in throughput of 10-400 percent compared to naive approaches.},
	number = {2},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Tovar, B. and Silva, R. F. da and Juve, G. and Deelman, E. and Allcock, W. and Thain, D. and Livny, M.},
	month = feb,
	year = {2018},
	keywords = {Feedback loop, automatic job sizing, automatic provision of resources, bioinformatics, bioinformatics workflows, High throughput computing (HTC), high throughput workflow, high-throughput scientific workflows, Internet, job sizing problem, job sizing strategy, Monitoring, online archive, Physics, Random access memory, records management, resource consumption, resource consumption distributions, Resource management, resource monitoring and enforcement, resource usage, Throughput, throughput and waste optimization, throughput physics, Tools, workflow management software},
	pages = {240--253},
	file = {IEEE Xplore Abstract Record:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/NQMWWVI7/8066333.html:text/html;IEEE Xplore Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/4STJFXS5/Tovar et al. - 2018 - A Job Sizing Strategy for High-Throughput Scientif.pdf:application/pdf}
}

@misc{noauthor_1_nodate,
	title = {(1) {Hyperledger} {Chat}},
	url = {https://chat.hyperledger.org/channel/fabric-sdk-java},
	urldate = {2018-06-07},
	file = {(1) Hyperledger Chat:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/ID4HIW9K/fabric-sdk-java.html:text/html}
}

@misc{noauthor_stop_nodate,
	title = {Stop and remove all docker containers and images {\textbar} {The} humble developer},
	url = {http://blog.baudson.de/blog/stop-and-remove-all-docker-containers-and-images},
	urldate = {2018-06-07},
	file = {Stop and remove all docker containers and images | The humble developer:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/4RHKZH2Q/stop-and-remove-all-docker-containers-and-images.html:text/html}
}

@article{glatard_flexible_2008,
	title = {Flexible and {Efficient} {Workflow} {Deployment} of {Data}-{Intensive} {Applications} {On} {Grids} {With} {MOTEUR}},
	volume = {22},
	issn = {1094-3420},
	url = {http://dx.doi.org/10.1177/1094342008096067},
	doi = {10.1177/1094342008096067},
	abstract = {Workflows offer a powerful way to describe and deploy applications on grid infrastructures. Many workflow management systems have been proposed but there is still a lack of a system that would allow both a simple description of the dataflow of the application and an efficient execution on a grid platform. In this paper, we study the requirements of such a system, underlining the need for well-defined data composition strategies on the one hand and for a fully parallel execution on the other. As combining those features is not straightforward, we then propose algorithms to do so and we describe the design and implementation of MOTEUR, a workflow engine that fulfills those requirements. Performance results and overhead quantification are shown to evaluate MOTEUR with respect to existing comparable workflow systems on a production grid.},
	number = {3},
	urldate = {2018-07-03},
	journal = {Int. J. High Perform. Comput. Appl.},
	author = {Glatard, Tristan and Montagnat, Johan and Lingrand, Diane and Pennec, Xavier},
	month = aug,
	year = {2008},
	keywords = {data composition operators, grids, services, workflows},
	pages = {347--360}
}

@article{ogasawara_chiron:_nodate,
	title = {Chiron: a parallel engine for algebraic scientific workflows},
	volume = {25},
	copyright = {Copyright © 2013 John Wiley \& Sons, Ltd.},
	issn = {1532-0634},
	shorttitle = {Chiron},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3032},
	doi = {10.1002/cpe.3032},
	abstract = {Large-scale scientific experiments based on computer simulations are typically modeled as scientific workflows, which eases the chaining of different programs. These scientific workflows are defined, executed, and monitored by scientific workflow management systems (SWfMS). As these experiments manage large amounts of data, it becomes critical to execute them in high-performance computing environments, such as clusters, grids, and clouds. However, few SWfMS provide parallel support. The ones that do so are usually labor-intensive for workflow developers and have limited primitives to optimize workflow execution. To address these issues, we developed workflow algebra to specify and enable the optimization of parallel execution of scientific workflows. In this paper, we show how the workflow algebra is efficiently implemented in Chiron, an algebraic based parallel scientific workflow engine. Chiron has a unique native distributed provenance mechanism that enables runtime queries in a relational database. We developed two studies to evaluate the performance of our algebraic approach implemented in Chiron; the first study compares Chiron with different approaches, whereas the second one evaluates the scalability of Chiron. By analyzing the results, we conclude that Chiron is efficient in executing scientific workflows, with the benefits of declarative specification and runtime provenance support. Copyright © 2013 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {16},
	urldate = {2018-07-03},
	journal = {Concurrency and Computation: Practice and Experience},
	author = {Ogasawara, Eduardo and Dias, Jonas and Silva, Vitor and Chirigati, Fernando and Oliveira, Daniel de and Porto, Fabio and Valduriez, Patrick and Mattoso, Marta},
	keywords = {scientific workflows, parallel execution, provenance},
	pages = {2327--2341},
	file = {Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/FHFAIBQM/Ogasawara et al. - Chiron a parallel engine for algebraic scientific.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/PL74JVHY/cpe.html:text/html}
}

@article{wolstencroft_taverna_2013,
	title = {The {Taverna} workflow suite: designing and executing workflows of {Web} {Services} on the desktop, web or in the cloud},
	volume = {41},
	issn = {0305-1048},
	shorttitle = {The {Taverna} workflow suite},
	url = {https://academic.oup.com/nar/article/41/W1/W557/1094153},
	doi = {10.1093/nar/gkt328},
	abstract = {Abstract.  The Taverna workflow tool suite (http://www.taverna.org.uk) is designed to combine distributed Web Services and/or local tools into complex analysis},
	language = {en},
	number = {W1},
	urldate = {2018-07-11},
	journal = {Nucleic Acids Res},
	author = {Wolstencroft, Katherine and Haines, Robert and Fellows, Donal and Williams, Alan and Withers, David and Owen, Stuart and Soiland-Reyes, Stian and Dunlop, Ian and Nenadic, Aleksandra and Fisher, Paul and Bhagat, Jiten and Belhajjame, Khalid and Bacall, Finn and Hardisty, Alex and Nieva de la Hidalga, Abraham and Vargas, Balcazar and P, Maria and Sufi, Shoaib and Goble, Carole},
	month = jul,
	year = {2013},
	pages = {W557--W561},
	file = {Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/QQ4LF7WC/Wolstencroft et al. - 2013 - The Taverna workflow suite designing and executin.pdf:application/pdf;Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/9C42ZDL8/1094153.html:text/html}
}

@article{billings_eclipse_2018,
	title = {The eclipse integrated computational environment},
	volume = {7},
	issn = {2352-7110},
	url = {http://www.sciencedirect.com/science/article/pii/S235271101830133X},
	doi = {10.1016/j.softx.2018.07.004},
	abstract = {Problems in modeling and simulation require significantly different workflow management technologies from standard grid-based workflow management systems. Computational scientists typically interact with simulation software in a feedback-driven way where solutions and workflows are developed iteratively and simultaneously. This work describes common modeling and simulation activities and how combinations of these activities form unique workflows. We present the Eclipse Integrated Computational Environment as a workflow management system and development environment for the modeling and simulation community. Examples of the Environment’s applicability to problems in energy science, general multiphysics simulations, quantum computing, and other areas are presented along with its impact on the community at large.},
	urldate = {2018-08-01},
	journal = {SoftwareX},
	author = {Billings, Jay Jay and Bennett, Andrew R. and Deyton, Jordan and Gammeltoft, Kasper and Graham, Jonah and Gorin, Dasha and Krishnan, Hari and Li, Menghan and McCaskey, Alexander J. and Patterson, Taylor and Smith, Robert and Watson, Gregory R. and Wojtowicz, Anna},
	month = jan,
	year = {2018},
	keywords = {Eclipse, Workflows, Supercomputing, Usability, Workflow management},
	pages = {234--244},
	file = {ScienceDirect Full Text PDF:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/J2KC72UW/Billings et al. - 2018 - The eclipse integrated computational environment.pdf:application/pdf;ScienceDirect Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/VA37ANMD/S235271101830133X.html:text/html}
}

@misc{noauthor_tutorial_nodate,
	title = {Tutorial 4: {Introducing} {RDFS} \& {OWL}},
	url = {http://www.linkeddatatools.com/introducing-rdfs-owl},
	urldate = {2018-11-12},
	file = {Tutorial 4\: Introducing RDFS & OWL:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/RR74JD54/introducing-rdfs-owl.html:text/html}
}

@misc{noauthor_rdf_nodate,
	title = {{RDF} {Containers}},
	url = {http://w3schools.sinsixx.com/rdf/rdf_containers.asp.htm},
	urldate = {2018-11-12},
	file = {RDF Containers:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/3K3LMSVU/rdf_containers.asp.html:text/html}
}

@misc{noauthor_interface_2018,
	title = {Interface description language},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Interface_description_language&oldid=859882161},
	abstract = {An interface description language or interface definition language (IDL), is a specification language used to describe a software component's application programming interface (API). IDLs describe an interface in a language-independent way, enabling communication between software components that do not share one language. For example, between those written in C++ and those written in Java.
IDLs are commonly used in remote procedure call software. In these cases the machines at either end of the link may be using different operating systems and computer languages. IDLs offer a bridge between the two different systems.
Software systems based on IDLs include Sun's ONC RPC, The Open Group's Distributed Computing Environment, IBM's System Object Model, the Object Management Group's CORBA (which implements OMG IDL, an IDL based on DCE/RPC) and Data Distribution Service, Mozilla's XPCOM, Facebook's Thrift and WSDL for Web services.},
	language = {en},
	urldate = {2018-11-15},
	journal = {Wikipedia},
	month = sep,
	year = {2018},
	note = {Page Version ID: 859882161},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/857LUCAM/index.html:text/html}
}

@misc{noauthor_common_nodate,
	title = {Common {Workflow} {Language} ({CWL}) {Workflow} {Description}, v1.0.2},
	url = {https://www.commonwl.org/v1.0/Workflow.html},
	urldate = {2018-11-15},
	file = {Common Workflow Language (CWL) Workflow Description, v1.0.2:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/WN9QD872/Workflow.html:text/html}
}

@misc{noauthor_about_nodate,
	title = {About the {Interface} {Definition} {Language} {Specification} {Version} 4.2},
	url = {https://www.omg.org/spec/IDL/About-IDL/},
	urldate = {2018-11-15},
	file = {About the Interface Definition Language Specification Version 4.2:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/VIP2RIIW/About-IDL.html:text/html}
}

@misc{noauthor_rdf_nodate-1,
	title = {{RDF} {Interfaces}},
	url = {https://www.w3.org/TR/rdf-interfaces/},
	urldate = {2018-11-15},
	file = {RDF Interfaces:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/7IDWSGBP/rdf-interfaces.html:text/html}
}

@misc{noauthor_universally_nodate,
	title = {A {Universally} {Unique} {IDentifier} ({UUID}) {URN} {Namespace}},
	url = {https://www.ietf.org/rfc/rfc4122.txt},
	urldate = {2018-12-13},
	file = {:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/28BHSGGW/rfc4122.html:text/html}
}

@misc{noauthor_semantic_nodate,
	title = {semantic web - {Generating} {URIs} in {Jena} for {RDF} - {Stack} {Overflow}},
	url = {https://stackoverflow.com/questions/7722143/generating-uris-in-jena-for-rdf},
	urldate = {2018-12-13},
	file = {semantic web - Generating URIs in Jena for RDF - Stack Overflow:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/2585HPSE/generating-uris-in-jena-for-rdf.html:text/html}
}

@misc{noauthor_iri_nodate,
	title = {{IRI}, {URI}, {URL}, {URN} and their differences – {Fusion}},
	url = {http://fusion.cs.uni-jena.de/fusion/blog/2016/11/18/iri-uri-url-urn-and-their-differences/},
	language = {de},
	urldate = {2018-12-13},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/P69TDZWP/iri-uri-url-urn-and-their-differences.html:text/html}
}

@misc{noauthor_owl_nodate,
	title = {{OWL} {Web} {Ontology} {Language} {Guide}},
	url = {https://www.w3.org/TR/owl-guide/},
	urldate = {2018-12-13},
	file = {OWL Web Ontology Language Guide:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/Q9Z6IFN3/owl-guide.html:text/html}
}

@misc{noauthor_shacl_nodate,
	title = {{SHACL} and {OWL} {Compared}},
	url = {http://spinrdf.org/shacl-and-owl.html},
	urldate = {2019-02-01},
	file = {SHACL and OWL Compared:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/SUAQ8SB7/shacl-and-owl.html:text/html}
}

@misc{noauthor_using_nodate,
	title = {Using {Jena} and {SHACL} to {Validate} {RDF} {Data} - {DZone} {Big} {Data}},
	url = {https://dzone.com/articles/using-jena-and-shacl-to-validate-rdf-data},
	abstract = {A software architect gives a quick tutorial on how to to validate data from an RDF dataset using the SHACL (Shape Constraint Language), a W3C standard.},
	language = {en},
	urldate = {2019-02-01},
	journal = {dzone.com},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/TCP9CDVZ/using-jena-and-shacl-to-validate-rdf-data.html:text/html}
}

@misc{noauthor_rule_nodate,
	title = {Rule {Execution} {With} {SHACL} - {DZone} {Big} {Data}},
	url = {https://dzone.com/articles/rule-execution-with-shacl},
	abstract = {A developer gives a quick look into using SHACL to perform rule execution on RDF data, and provides all the Turtle and Java code necessary to get started.},
	language = {en},
	urldate = {2019-02-01},
	journal = {dzone.com},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/2CY3DHGX/rule-execution-with-shacl.html:text/html}
}

@misc{noauthor_apache_nodate,
	title = {Apache {Jena} - {Reasoners} and rule engines: {Jena} inference support},
	url = {https://jena.apache.org/documentation/inference/},
	urldate = {2019-02-01},
	file = {Apache Jena - Reasoners and rule engines\: Jena inference support:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/LPVMUFK9/inference.html:text/html}
}

@misc{noauthor_function_nodate,
	title = {The {Function} {Ontology}},
	url = {https://fno.io/spec/},
	language = {en},
	urldate = {2019-02-06},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/8SU83DCL/spec.html:text/html}
}

@misc{noauthor_hydra_nodate,
	title = {Hydra {Core} {Vocabulary}},
	url = {http://www.hydra-cg.com/spec/latest/core/},
	urldate = {2019-02-06},
	file = {Hydra Core Vocabulary:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/7GTHFRQS/core.html:text/html}
}

@misc{noauthor_owl-s:_nodate,
	title = {{OWL}-{S}: {Semantic} {Markup} for {Web} {Services}},
	url = {https://www.w3.org/Submission/OWL-S/},
	urldate = {2019-02-06},
	file = {OWL-S\: Semantic Markup for Web Services:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/2XLCQSPI/OWL-S.html:text/html}
}

@misc{draper_getting_2017,
	title = {Getting started with {RDF} {SPARQL} queries and inference using {Apache} {Jena} {Fuseki}},
	url = {https://christinemdraper.wordpress.com/2017/04/09/getting-started-with-rdf-sparql-jena-fuseki/},
	abstract = {This post describes how to get started using the Apache Jena RDF Server (Fuseki) to perform basic SPARQL queries and inference. Apache Jena is an open-source framework for building semantic web app…},
	language = {en},
	urldate = {2019-02-22},
	journal = {Graphs and Chef and Javascript - oh my!},
	author = {Draper, Christine},
	month = apr,
	year = {2017},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/ML8YLE57/getting-started-with-rdf-sparql-jena-fuseki.html:text/html}
}

@misc{memorynotfound_apache_2017,
	title = {Apache {HttpClient} 4.5 {HTML} {FORM} {POST} {Example}},
	url = {https://memorynotfound.com/apache-httpclient-html-form-post-example/},
	abstract = {Apache HttpClient provides the entity class UrlEncodedFormEntity to submit HTML Form parameters to the server. To simulate ...},
	language = {en-US},
	urldate = {2019-03-01},
	journal = {Memorynotfound},
	author = {{MemoryNotFound}},
	month = may,
	year = {2017},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/7296EU2V/apache-httpclient-html-form-post-example.html:text/html}
}

@misc{noauthor_dcmi:_nodate,
	title = {{DCMI}: {DCMI} {Metadata} expressed in {RDF} {Schema} {Language}},
	url = {http://dublincore.org/schemas/rdfs/},
	urldate = {2019-03-26},
	file = {DCMI\: DCMI Metadata expressed in RDF Schema Language:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/WEAV3MB8/rdfs.html:text/html}
}

@misc{noauthor_dublin_nodate,
	title = {Dublin {Core} dctype},
	url = {http://dublincore.org/2012/06/14/dctype.rdf},
	urldate = {2019-03-26},
	file = {:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/9MTID3GD/dctype.html:text/html}
}

@misc{noauthor_automatically_2019,
	title = {Automatically exported from code.google.com/p/collections-ontology: collections-ontology/collections-ontology},
	shorttitle = {Automatically exported from code.google.com/p/collections-ontology},
	url = {https://github.com/collections-ontology/collections-ontology},
	urldate = {2019-03-27},
	publisher = {collections-ontology},
	month = jan,
	year = {2019},
	note = {original-date: 2015-03-19T12:10:52Z}
}

@misc{noauthor_review_nodate,
	title = {A {Review} of {Java} {Template} {Engines} - {DZone} {Web} {Dev}},
	url = {https://dzone.com/articles/template-engines-at-one-spring-boot-and-engines-se},
	abstract = {In this article, Miro Kopecky provides a thorough review of Java template engines Apache Velocity, Apache FreeMarker, Thymeleaf, and Pebble.},
	language = {en},
	urldate = {2019-04-03},
	journal = {dzone.com},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/WEUEWLLY/template-engines-at-one-spring-boot-and-engines-se.html:text/html}
}

@misc{noauthor_xturtle_nodate,
	title = {Xturtle — {Agile} {Knowledge} {Engineering} and {Semantic} {Web} ({AKSW})},
	url = {http://aksw.org/Projects/Xturtle.html},
	urldate = {2019-04-03},
	file = {Xturtle — Agile Knowledge Engineering and Semantic Web (AKSW):/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/CWTRBE76/Xturtle.html:text/html}
}

@misc{noauthor_seafood_nodate,
	title = {Seafood {Without} {The} {Sea}: {Will} {Lab}-{Grown} {Fish} {Hook} {Consumers}?},
	shorttitle = {Seafood {Without} {The} {Sea}},
	url = {https://www.npr.org/sections/thesalt/2019/05/05/720041152/seafood-without-the-sea-will-lab-grown-fish-hook-consumers},
	abstract = {The seafood industry has some well-publicized problems: from overfishing to contaminants that make their way into fish. Now, a handful of startups aim to offer a "clean" alternative grown from cells.},
	language = {en},
	urldate = {2019-05-11},
	journal = {NPR.org},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/8YNTUIHU/seafood-without-the-sea-will-lab-grown-fish-hook-consumers.html:text/html}
}

@book{euzenat_ontology_2013,
	address = {Berlin, Heidelberg},
	title = {Ontology {Matching}},
	isbn = {978-3-642-38720-3 978-3-642-38721-0},
	url = {http://link.springer.com/10.1007/978-3-642-38721-0},
	language = {en},
	urldate = {2019-04-28},
	publisher = {Springer Berlin Heidelberg},
	author = {Euzenat, Jérôme and Shvaiko, Pavel},
	year = {2013},
	doi = {10.1007/978-3-642-38721-0}
}

@misc{noauthor_networkx_nodate,
	title = {networkx - {How} to set the output size in {GraphViz} for the dot format?},
	url = {https://stackoverflow.com/questions/14784405/how-to-set-the-output-size-in-graphviz-for-the-dot-format},
	urldate = {2019-04-28},
	journal = {Stack Overflow},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/85ARYGXP/how-to-set-the-output-size-in-graphviz-for-the-dot-format.html:text/html}
}

@misc{noauthor_pegasus_nodate,
	title = {Pegasus {WMS} – {Automate}, recover, and debug scientific computations},
	url = {https://pegasus.isi.edu/},
	language = {en},
	urldate = {2019-04-28},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/6I3UG4WW/pegasus.isi.edu.html:text/html}
}

@misc{noauthor_scidata_nodate,
	title = {{SciData} - {A} {Scientific} {Data} {Model}},
	url = {http://stuchalk.github.io/scidata/},
	urldate = {2019-04-28},
	file = {SciData - A Scientific Data Model:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/JTHQYMYW/scidata.html:text/html}
}

@misc{noauthor_deri_nodate,
	title = {{DERI} {Vocabularies}},
	url = {http://vocab.deri.ie/cogs.html},
	urldate = {2019-04-28},
	file = {DERI Vocabularies:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/UM34U4BT/cogs.html:text/html}
}

@misc{noauthor_vocals:_nodate,
	title = {{VoCaLS}: {A} {Vocabulary} {Catalog} for {Linked} {Streams}},
	url = {https://ysedira.github.io/vocals/docs/core/index-en.html#RDFStream},
	urldate = {2019-04-28},
	file = {:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/8MIX9CSM/index-en.html:text/html}
}

@misc{kuba_[protege-owl]_2011,
	title = {[protege-owl] {Enumerated} type in {Protege} {OWL}},
	url = {https://mailman.stanford.edu/pipermail/protege-owl/2011-June/016869.html},
	urldate = {2019-04-28},
	author = {Kuba, Martin},
	month = jun,
	year = {2011},
	file = {snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/I8B5NUDL/016869.html:text/html}
}

@misc{noauthor_introduction_nodate,
	title = {Introduction - {Introduction} to ontologies and semantic web - tutorial},
	url = {https://www.obitko.com/tutorials/ontologies-semantic-web/introduction.html},
	urldate = {2019-04-28},
	file = {Introduction - Introduction to ontologies and semantic web - tutorial:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/IH5ATTRX/introduction.html:text/html}
}

@misc{noauthor_owl_nodate-1,
	title = {{OWL} {Test} 7.4.1. {Examples} from the {OWL} {Guide}},
	url = {https://www.w3.org/TR/owl-test/misc-000-guide},
	urldate = {2019-04-27},
	file = {OWL Test 7.4.1. Examples from the OWL Guide:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/3PX7MWVR/misc-000-guide.html:text/html}
}

@misc{noauthor_owl_nodate-2,
	title = {{OWL} {Web} {Ontology} {Language} {Reference}},
	url = {https://www.w3.org/TR/owl-ref/#CardinalityRestriction},
	urldate = {2019-04-27},
	file = {OWL Web Ontology Language Reference:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/DTZYIU3B/owl-ref.html:text/html}
}

@misc{noauthor_how_nodate,
	title = {How to {Activate} {Your} {Brain}’s {Ability} to {Learn} - {Popular} {Science}},
	url = {http://getpocket.com/explore/item/how-to-activate-your-brain-s-ability-to-learn},
	abstract = {The power of practicing well beyond mastery.},
	urldate = {2019-05-23},
	journal = {Pocket},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/J3BEHCLG/how-to-activate-your-brain-s-ability-to-learn.html:text/html}
}

@misc{noauthor_spring_nodate,
	title = {Spring {Statemachine} - {Reference} {Documentation}},
	url = {https://docs.spring.io/spring-statemachine/docs/2.1.2.RELEASE/reference/#crashcourse},
	urldate = {2019-05-27},
	file = {Spring Statemachine - Reference Documentation:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/WHQLG85N/reference.html:text/html}
}

@misc{noauthor_spring_nodate-1,
	title = {spring - {How} do {I} find the library containing org.springframework.stereotype.{Service}?},
	url = {https://stackoverflow.com/questions/25206487/how-do-i-find-the-library-containing-org-springframework-stereotype-service},
	urldate = {2019-06-04},
	journal = {Stack Overflow},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/CLFDEDHE/how-do-i-find-the-library-containing-org-springframework-stereotype-service.html:text/html}
}

@misc{noauthor_java_nodate,
	title = {Java {Tutorial} - {Java} {Files}.move({Path} source, {Path} target, {CopyOption} ... options)},
	url = {http://www.java2s.com/Tutorials/Java/java.nio.file/Files/Java_Files_move_Path_source_Path_target_CopyOption_options_.htm},
	urldate = {2019-06-04},
	file = {Java Tutorial - Java Files.move(Path source, Path target, CopyOption ... options):/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/P6RCFDW9/Java_Files_move_Path_source_Path_target_CopyOption_options_.html:text/html}
}

@misc{noauthor_eclipse_nodate,
	title = {Eclipse {Git} repositories},
	url = {https://git.eclipse.org/c/ptp},
	urldate = {2019-06-06},
	file = {Eclipse Git repositories:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/9MPMHG39/ptp.html:text/html}
}

@misc{billings_ice_2019,
	title = {Ice {Project} {Main} repo. {Contribute} to eclipse/ice development by creating an account on {GitHub}},
	copyright = {EPL-1.0},
	url = {https://github.com/eclipse/ice},
	urldate = {2019-06-16},
	publisher = {Eclipse Foundation},
	author = {Billings, Jay Jay},
	month = apr,
	year = {2019},
	note = {original-date: 2014-06-24T18:20:00Z}
}

@misc{noauthor_owl_nodate-3,
	title = {{OWL} 2 {Web} {Ontology} {Language} {Document} {Overview} ({Second} {Edition})},
	url = {https://www.w3.org/TR/owl2-overview/#Ontologies},
	urldate = {2019-06-21},
	file = {OWL 2 Web Ontology Language Document Overview (Second Edition):/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/DXQ3RQWC/owl2-overview.html:text/html}
}

@misc{noauthor_rdf_nodate-2,
	title = {{RDF} - {Semantic} {Web} {Standards}},
	url = {https://www.w3.org/RDF/},
	urldate = {2019-06-23},
	file = {RDF - Semantic Web Standards:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/T7IQ5MZS/RDF.html:text/html}
}

@misc{noauthor_rdf_nodate-3,
	title = {{RDF} 1.1 {Concepts} and {Abstract} {Syntax}},
	url = {https://www.w3.org/TR/rdf11-concepts/},
	urldate = {2019-06-23},
	file = {RDF 1.1 Concepts and Abstract Syntax:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/Y2SX6XNP/rdf11-concepts.html:text/html}
}

@misc{noauthor_resource_2019,
	title = {Resource {Description} {Framework}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Resource_Description_Framework&oldid=898556519},
	abstract = {The Resource Description Framework (RDF) is a family of World Wide Web Consortium (W3C) specifications originally designed as a metadata data model. It has come to be used as a general method for conceptual description or modeling of information that is implemented in web resources, using a variety of syntax notations and data serialization formats. It is also used in knowledge management applications.
RDF was adopted as a W3C recommendation in 1999. The RDF 1.0 specification was published in 2004, the RDF 1.1 specification in 2014.},
	language = {en},
	urldate = {2019-06-23},
	journal = {Wikipedia},
	month = may,
	year = {2019},
	note = {Page Version ID: 898556519},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/M77SEJEP/index.html:text/html}
}

@misc{noauthor_rdf_nodate-4,
	title = {{RDF} 1.1 {Turtle}},
	url = {https://www.w3.org/TR/turtle/},
	urldate = {2019-06-23},
	file = {RDF 1.1 Turtle:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/CYGP2SLP/turtle.html:text/html}
}

@misc{noauthor_rdf_nodate-5,
	title = {{RDF} {Schema} 1.1},
	url = {https://www.w3.org/TR/rdf-schema/},
	urldate = {2019-06-23},
	file = {RDF Schema 1.1:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/VQLB6BX6/rdf-schema.html:text/html}
}

@misc{noauthor_linked_nodate,
	title = {Linked {Data} {Applications}},
	url = {http://linkeddata.es/},
	urldate = {2019-06-24},
	file = {Linked Data Applications:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/5G9QYY9A/linkeddata.es.html:text/html}
}

@misc{noauthor_linked_nodate-1,
	title = {Linked {Open} {Vocabularies} ({LOV})},
	url = {https://lov.linkeddata.es/dataset/lov/},
	abstract = {Your entry point to high quality and reusable Vocabularies to describe Linked Data.},
	language = {en},
	urldate = {2019-06-24},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/3CDUUG6D/lov.html:text/html}
}

@misc{noauthor_web_nodate,
	title = {Web {Ontology} {Language} ({OWL}) {Abstract} {Syntax} and {Semantics}},
	url = {https://www.w3.org/TR/2003/WD-owl-semantics-20030203/semantics.html},
	urldate = {2019-06-25},
	file = {Web Ontology Language (OWL) Abstract Syntax and Semantics:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/Q5QLSM5Q/semantics.html:text/html}
}

@misc{noauthor_protege_nodate,
	title = {protégé},
	url = {https://protege.stanford.edu/},
	urldate = {2019-06-25},
	file = {protégé:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/QUHHSTBD/protege.stanford.edu.html:text/html}
}

@misc{noauthor_apache_nodate-1,
	title = {Apache {Jena} -},
	url = {https://jena.apache.org/},
	urldate = {2019-06-26},
	file = {Apache Jena -:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/D4W24YCR/jena.apache.org.html:text/html}
}

@misc{noauthor_graphviz_nodate,
	title = {Graphviz - {Graph} {Visualization} {Software}},
	url = {https://www.graphviz.org/},
	urldate = {2019-06-29},
	file = {Graphviz - Graph Visualization Software:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/Q4YBF76X/www.graphviz.org.html:text/html}
}

@misc{noauthor_ont-api_2019,
	title = {{ONT}-{API} ({OWL}-{API} over {Apache} {Jena}). {Contribute} to avicomp/ont-api development by creating an account on {GitHub}},
	url = {https://github.com/avicomp/ont-api},
	urldate = {2019-06-29},
	publisher = {Avicomp Services, AO},
	month = jun,
	year = {2019},
	note = {original-date: 2017-06-13T15:24:40Z}
}

@misc{noauthor_owl_nodate-4,
	title = {{OWL} {API}, {Jena} {API}, {Protege} {API}, which one to use - {Stack} {Overflow}},
	url = {https://stackoverflow.com/questions/17567771/owl-api-jena-api-protege-api-which-one-to-use},
	urldate = {2019-06-29},
	file = {OWL API, Jena API, Protege API, which one to use - Stack Overflow:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/KU5HQID7/owl-api-jena-api-protege-api-which-one-to-use.html:text/html}
}

@misc{noauthor_cylc_nodate,
	title = {cylc - a workflow engine},
	url = {https://cylc.github.io/},
	urldate = {2019-07-04},
	file = {cylc - a workflow engine:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/IA95U2DF/cylc.github.io.html:text/html}
}

@misc{noauthor_xslt_nodate,
	title = {{XSLT} {\textgreater}{\textgreater} {Elements} {\textgreater}{\textgreater} xsl:text},
	shorttitle = {{XSLT} {\textgreater}{\textgreater} {Elements} {\textgreater}{\textgreater} xsl},
	url = {http://www.devguru.com/content/technologies/xslt/elements-xsltext.html},
	abstract = {XSLT » Elements » xsl:text Syntax: {\textless}xsl:text  disable-output-escaping="yes" {\textbar} "no"{\textgreater}{\textless}/xsl:text{\textgreater}The xsl:text element is used to add literal text to the output. This element cannot contain any other XSL elements. It can only contain text.},
	language = {en},
	urldate = {2019-07-04},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/BMU97SV9/elements-xsltext.html:text/html}
}

@misc{noauthor_java_nodate-1,
	title = {java - {Programmatically} {Start} {OSGi} ({Equinox})?},
	url = {https://stackoverflow.com/questions/4673406/programmatically-start-osgi-equinox/4673904},
	urldate = {2019-07-05},
	journal = {Stack Overflow},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/7WB8S2Z8/4673904.html:text/html}
}

@misc{noauthor_workflow_nodate,
	title = {Workflow {Examples} – {Pegasus} {WMS}},
	url = {https://pegasus.isi.edu/documentation/examples/},
	language = {en},
	urldate = {2019-07-07},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/EJPDRB6D/examples.html:text/html}
}

@misc{noauthor_xslt_nodate-1,
	title = {{XSLT} {Basic} {Example}},
	url = {https://developer.mozilla.org/en-US/docs/Web/API/XSLTProcessor/Basic_Example},
	abstract = {This first example demonstrates the basics of setting up an XSLT transformation in a browser. The example will take an XML document that contains information (title, list of authors and body text) about an article and present it in an human readable form.},
	language = {en},
	urldate = {2019-07-07},
	journal = {MDN Web Docs},
	file = {Snapshot:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/VLR8QER2/Basic_Example.html:text/html}
}

@book{gomez_semantic_2019,
	title = {{SEMANTIC} {INFORMATION} {AND} {PHYSICAL} {MULTI}-{DOMAIN} {MODELING} {AND} {SIMULATION} {FOR} {POWER} {SYSTEMS}},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-247635},
	abstract = {There are different reasons for combining different modeling languages and simulation languages: Exchange of more detailed information about power network components, their parameters and, most importantly, mathematical equations describing their behavior and the exchange of a mathematical description, using equation-based languages (e.g.: Modelica), allows models to be detached from the mathematical solver. This leads to the development of new APIs within software tools, which can handle standardized modeling language used for model implementation. Furthermore, the mathematical description of models and the integration of new simulation standards, such as the FMI, could help avoiding ambiguities on how power system models are implemented, by providing additional means for the exchange of the complete description of models or parts of a model between software tools. The aim of this thesis is to provide a new approach for the development of power systems modeling and simulation software tools. The thesis is focused on proposing new methods, based on available information and simulation standards for the exchange, modeling, and simulation of power systems dynamic models; and to show a proof of concept of the feasibility of the proposed methods. To this aims, the Common Information Model (CIM) for the modeling and exchange of power system information is studied. Furthermore, the equation-based language Modelica is described and proposed with the aim of complementing the use of the CIM for the modeling and simulation of those dynamics models. The application of these standards lead to a different view on the modeling and simulation of power dynamic network models. The conventional view is that of black box modeling. The implementation of network model components is strongly connected to the simulation software tool used for steady-state and dynamics calculations. Thus, a modeler or test engineer only has access to the parameters of a model and relies on the software capabilities to calculate the states and the behavior of that model. This thesis proposes a different view per the application of the white box modeling and simulation concept: full detail and transparency on the development of a mathematical description of power system components and discrete events. Moreover, the combination of information standards with equation-based standards to produce network models allows full access and manipulation of the complete model details. Finally, transparency regarding the implementation of software tools can support either information-based, equations-based languages or simulation standards, which are suitable for simulation of dynamic network models.},
	language = {en},
	urldate = {2019-07-13},
	author = {Gómez, Francisco José and Vanfretti, Luigi and Olsen, Svein and Palensky, Peter and {SmarTSLab} and {KTH} and {Skolan för elektroteknik och datavetenskap (EECS)}},
	year = {2019},
	note = {OCLC: 1090996485},
	file = {Gómez et al. - 2019 - SEMANTIC INFORMATION AND PHYSICAL MULTI-DOMAIN MOD.pdf:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/UEMULX4E/Gómez et al. - 2019 - SEMANTIC INFORMATION AND PHYSICAL MULTI-DOMAIN MOD.pdf:application/pdf}
}

@article{oliver_workflow_2019,
	title = {Workflow {Automation} for {Cycling} {Systems}},
	volume = {21},
	issn = {1521-9615, 1558-366X},
	url = {https://ieeexplore.ieee.org/document/8675433/},
	doi = {10.1109/MCSE.2019.2906593},
	number = {4},
	urldate = {2019-07-13},
	journal = {Comput. Sci. Eng.},
	author = {Oliver, Hilary and Shin, Matthew and Matthews, David and Sanders, Oliver and Bartholomew, Sadie and Clark, Andrew and Fitzpatrick, Ben and van Haren, Ronald and Hut, Rolf and Drost, Niels},
	month = jul,
	year = {2019},
	pages = {7--21}
}

@article{j_oliver_cylc:_2018,
	title = {Cylc: {A} {Workflow} {Engine} for {Cycling} {Systems}},
	volume = {3},
	issn = {2475-9066},
	shorttitle = {Cylc},
	url = {http://joss.theoj.org/papers/10.21105/joss.00737},
	doi = {10.21105/joss.00737},
	number = {27},
	urldate = {2019-07-13},
	journal = {JOSS},
	author = {J Oliver, Hilary and Shin, Matthew and Sanders, Oliver},
	month = jul,
	year = {2018},
	pages = {737},
	file = {Full Text:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/KJWEGFKJ/J Oliver et al. - 2018 - Cylc A Workflow Engine for Cycling Systems.pdf:application/pdf}
}

@misc{noauthor_cylc_nodate-1,
	title = {cylc - a workflow engine},
	url = {https://cylc.github.io/},
	urldate = {2019-07-13},
	file = {cylc - a workflow engine:/home/bkj/.zotero/zotero/xvg75ijy.default/zotero/storage/HTAZ592A/cylc.github.io.html:text/html}
}