\chapter{Conclusions and Future Work}\label{ch:conclusions}

It would certainly be fair to conclude that this work has a slight
epistemological flare. Much of this work is focused on the insistence that
different types of workflows can all be justifiably described as workflows.
While this is indeed epistemological, it is necessary in light of the extremely
great challenges posed by next-generation problems, etc. It is not sufficient to
merely assert equality in lieu of developing a sophisticated and beneficial
understanding.

Chapter \ref{ch:introduction} describes the problems that exist because of the
proliferation of scientific workflow management systems and thus the need for a
more common understanding. In an ideal world, it would be great for a set of
common building blocks to be adopted and used widely, but that remains highly
unlikely for the simple fact that developers, scientists, and other makers are
all busy people and the effort is costly. This phenomenon is well documented in
\cite{ogrady_new_2013}, which describes how developers, increasingly pressed to
deliver more with less, push for the solutions that make them more productive
and thus more valuable. It is easy to say that everyone would be more productive
with sophisticated common building blocks, but while years of effort are being
expended to make the one true set of common building blocks that will make
everyone productive, developers will be making tools that make them successful
and moving on to more complicated problems. Thus the best solution is develop a
common understanding of these tools and problems.

This conclusion is well supported by the narrative herein. While Chapter
\ref{ch:introduction} reviews many of the existing workflow technologies that
are commonly recognized, Chapter \ref{ch:eclipse-ice} presents a detailed
account of a modeling and simulation workflow management system, where decision
making, looping, human/intelligent agent intervention, and cycling all exist
within the same workflow. The examples of Chapter \ref{ch:workflow-ontology}
show that the workflow ontology can indeed be used to describe these different
types of workflows from the previous chapters in a consistent, semantic way.

Chapter \ref{ch:interoperability} concludes that although it is impossible to
apply the workflow ontology to enable interoperability in a broad sense because
of the significant differences between workflow management systems, it
remains possible for some systems. Furthermore, the decision-making power
provided by the workflow ontology is decoupled from the actual code that is
written to execute the workflows. Execution is not a requirement if value is
gained elsewhere, including in reasoning and planning.

One final conclusion of note is that the workflow ontology is better at
highlighting the differences between workflows than the similarities. The
examples of \S \ref{workflow-ont-examples} are unremarkable in their
similarities: they all have tasks gathered together that require some properties
and execute based on some order by dependency. The differences are the most
interesting part, with cycles and other features acting as key indicators of
topics in need of further investigation.

\section{Future Work}

A good body of future work could in principle be built off of this
thesis. What follows is a discussion of these opportunities and nascent ideas,
including more obvious efforts in ontologies and less obvious opportunities with
artificial intelligence.

\subsection{Execution and Data Ontologies}

Perhaps the most obvious area for future work is building on the work of others
described in Chapter \ref{ch:introduction} to develop an ontology for workflow
management systems. This was not pursued as part of this work in part because it
is largely covered by the work of Yu and Buyya, as discussed earlier. It would
be a relatively simple (but not trivial) exercise to convert their taxonomy to
an ontology. Lower nodes in their taxonomy would best be served by being
converted to object properties, just like the lower nodes in the example of \S
\ref{case-study} where crossovers and shared relationships were needed. This
ontology would be good companion to the workflow ontology of Chapter
\ref{ch:workflow-ontology}.

The other reason why this was not covered by this work is that there is little
debate within the community on what a workflow management system is. Workflow
management systems are easily recognized. However, as discussed herein, there
remains substantial debate on the definition of a scientific workflow; and thus
it is the more pressing area where research is needed. To put this another way:
while it would be valuable to have an ontology for workflow management systems,
they are much more understood than the workflows they execute.

Data ontologies are another area where some future work might exist. It is
questionable that endeavoring to create individual ontologies for all data
models is valuable and productive, but more general metamodels would be useful.
The SciData model is one such effort \cite{noauthor_scidata_nodate}. The
challenge for SciData and similar efforts is being descriptive enough to capture
data across multiple domains. Their value proposition applies to the future of
this work as well: uniformity (and/or transitivity) in data models increases
productivity and drives discovery by eliminating knowledge gaps and duplication.
Until sophisticated data metamodels are developed, adopted, and supported by
tooling ecosystems, the best but far from optimal solution is to use RDF, as was
done in the examples of \S \ref{workflow-ont-examples}.

\subsection{Artificial Intelligence for Workflows}

Humans are the ultimate tool builders; but perhaps more important, we are
especially good at recognizing when new tools are needed. Digging holes with
shovels is all well and good since it is much better than using our hands, but
excavators are far superior for large jobs. Never has this been more true than
in our quest to develop artificial intelligence and machine learning (AI/ML)
tools.

One extremely interesting possibility for the application of AI/ML is to develop
a platform that can automatically ingest new workflow engines and tasks into an
executable service framework based only on new software or data artifacts that
are dynamically discovered. Previous work on the Eclipse ICE project examined
this in the context of using grammar inference to automatically generate
workflow tasks, shims, and input/output routines for new workflow tasks,
\cite{bennett_rapid_2015}. The effort combined code generation tools from Xtext,
Backus-Naur forms in context-free grammars, and workflow tools to create a
capstone in an automation trend for the Eclipse ICE project: plugins that
required two or more weeks to write by hand when the project started could be
autogenerated in a fraction of a second eight years later with generative
models.

A similar but broader effort could be undertaken using the workflow ontology as
an intermediate object representation (IOR) for workflow models and a
microservices framework as the coupler for workflow management systems. The
conceptual workflow for hooking up a new workflow model and/or management system
would be as follows:
\begin{enumerate}
  \item Apply grammar inference tools to example workflows from the new system
  to learn the grammar.
  \item Probablistically match workflow elements to workflow ontology elements
  to map to the IOR.
  \item Use the grammar and the IOR to automatically generate input/output
  routines for manipulating workflows for the new system. 
  \item Generate a wrapper microservice for executing the new workflow
  management system.
\end{enumerate}

Such an effort would be difficult and could cover a decade or more of research.
It would benefit substantially from the graded approach of the workflow
ontology, which would allow for prioritization and focus in the early days and
could be expanded in later days, and from an ontology for workflow management
systems. The latter would make it much easier to generate the microservice
wrappers in step 4 of the conceptual workflow.

Using a microservice framework is important because of the technology
differences that exist across workflow management systems. It is unreasonable to
expect that all workflow management systems could be rebuilt into a single
executable binary.

There would be a number of advantages to an artificially intelligent workflow
management system that could couple to other systems. First, it would be able to
do workflow campaigns optimally and dynamically with little intervention from
humans. Resources could be allocated based not only on hardware type and
availability but also by the types of workflows that needed to be executed and
how those workflows could be subdivided. Second, it might also be possible to have
a degree of limited workflow interchangeability as well as interoperability
since translation between compatible types of workflows would be possible and
could determined on the fly. Third, it would be possible to develop an
ever-expanding catalog (and possibly marketplace) of reusable workflows since
the configuration learned by the AI/ML engine, as well as the newly generated
code, could be packaged and shared.

\subsection{Provenance Opportunities}

There are numerous opportunities related to managing workflow provenance,
particularly with respect to using blockchain technology effectively. One
key question that remains is how well provenance captured in a distributed
ledger can be used to quickly create new workflows based on the original.
Duplicating a transaction is a relatively straightforward thing and, in
principle, executing it might be straightforward as well.

It would be interesting to investigate how a new transaction can point to the
original transaction from which it was copied. Would it be as simple as adding a
secondary hash in the saved state that pointed to the parent? Or would it
require a “blocktree” that allowed branching instead of solely a blockchain/hash
list? In any case, the identity of the parent would seem to be important
provenance itself! Another important question is how deep the provenance tree
could go. Investigating the degree to which contracts could convert provenance
information to standard ledger state is an interesting topic for further
research since it would address compatibility issues between workflow and
provenance models.

Addressing these and other questions as part of an extensive pilot project would
be valuable. There are many open source distributed ledger frameworks, including
the previously mentioned Hyperledger, and a number of commercial solutions that
could keep the investigation focused on the science rather than extensive
software engineering. Success in this endeavor could create an entirely new way
of producing reproducible and reusable scientific workflows.

\section{Final Thoughts}

The most enjoyable aspects of any thesis were covered in the previous two
sections: reflecting on its implications and opining on the new things that
can be done. Both of these reflect the fact that a thesis is merely the start
of a greater journey, and that end really represents the start of a new
beginning.

The start of that journey for scientific workflows is not in building more
highly threaded workflow management systems or better data formats. There are
enough of those. Instead, an understanding of the very definition of what a
scientific workflow is and how and why they change is required. Only when the
nature of workflows is understood, which one can hope will be aided in some small
way by this work, can the journey truly get under way.